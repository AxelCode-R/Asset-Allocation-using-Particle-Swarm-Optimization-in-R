---
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---
# Particle Swarm Optimization (PSO) {#spso}
The PSO was developed by J. Kennedy as a global optimization method based on swarm intelligence and presented to the public in 1995 by Eberhart and Kennedy [@KeEb1995]. The original PSO was intended to resemble a flock of birds flying through the sky without collisions. Therefore, its first applications were found in particle physics to analyze moving particles in high-dimensional spaces, which the name Particle recalls. Later, it was adapted in Evolutionary Computation to exploit a set of potential solutions in high dimensions and to find the optima by cooperating with other particles in the swarm [@PaVr2002]. Since it does not require gradient information, it is easier to apply than other global optimization methods. It can find the optimum by considering only the result of the function to be optimized. This means that the function can be arbitrarily complex and it is still possible to reach the global optimum. Other advantages are the low computational costs, since only basic mathematical operators are used, the extensibility and the simplicity.

## The Algorithm
Each particle $d$ with position $x_d$ moves in the search space $\mathbb{R}^N$ and has its own velocity $v_d$ and remembers its previous best position $p_{p,d}$. After each iteration, the velocity changes in the direction of the intrinsic velocity, the best previous position, and the global best position $p_g$ of all particles. A position change from $i$ to $i+1$ can be calculated by the following two equations [@PaVr2002]:

$$
\begin{aligned}
  v_d^{i+1} &= wv_d^{i} + c_p r_1^{i(d)} (p_{p,d}^i - x_d^i) + c_g r_2^{i(d)} (p_g^i - x_d^i) \\
  x_d^{i+1} &= x_d^i + v_d^{i+1}
\end{aligned}
$$

Where $r_1^{i(d)}$ and $r_2^{i(d)}$ are uniformly distributed random numbers in $[0, 1]$. The cognitive parameter $c_p$ acts as a weighting of the direction to its previous best position of the particle. This contrasts with the social parameter $c_g$, which is a weighting of the direction to the global best position. The inertial weight $w$ is crucial for the convergence behavior by remembering part of its previous trajectory. A study reviewed in [@PaVr2002] showed that these parameters can be set to $c_p=c_g=0.5$ and $w$ should decrease from $1.2$ to $0$. However, some problems benefit from a more precise tuning of these parameters. To allow effortless translation to code, the above formula for $d = 1, 2, \cdots, D$ particles can be given in the following matrix notation:

$$
\begin{aligned}
  V^{i+1} &= w \cdot V^{i} + c_p \cdot (\vec{r}_1^{\,i} \cdot (P^i-X^i)^T)^T + c_g \cdot (\vec{r}_2^{\,i} \cdot (p_g^i - X^i)^T)^T \\
  X^{i+1} &= X^i + V^{i+1}
\end{aligned}
$$

With current positions $X \in \mathbb{R}^{N \times D}$, current velocities $V \in \mathbb{R}^{N \times D}$, previous best positions $P \in \mathbb{R}^{N \times D}$, and global best position $p_g \in \mathbb{R}^{N}$. The parameters $w$, $c_p$ and $c_g$ are stile scalars. The random numbers $r_1$ and $r_2$ are replaced by the vectors $\vec{r}_1$ and $\vec{r}_2$, in which each element is a uniformly distributed random number generated in $[0, 1]$. The first transpose is needed to multiply each random number element-wise with each column and the second transpose transforms it back to the format of $V$ and $X$.

The algorithm mentioned above is the first published variant of PSO and is therefore referred to as standard PSO in this thesis. There are also other names like global PSO, because the information is distributed globally over all particles in the swarm and some also call it the basic or original PSO.


## `pso()` Function
In this section, a general PSO function is created that follows the structure of other optimization heuristics in R, in particular the existing PSO implementation from the R package `pso`. The key component of the problem is a objective function called `fn()`, which needs a vector that describes the position of one particle (e.g. weights) and returns a scalar that needs to be minimized. The other main parameter for the PSO function is `par`, which is a position of a particle used to derive the dimension of the problem and used as the initial position of one particle. The vector can contain only `NA`'s, resulting in completely random starting positions. The last two arguments are `lower` and `upper` bounds (e.g. weights greater than 0 and less than 1). All other parameters have default values that can be overridden by passing a list called `control`. The resulting structure is:


```{r pso1, eval=F}
pso <- function(
    par, 
    fn, 
    lower, 
    upper, 
    control = list()
  ){

}
```


Before the main data structure can be initialized, some sample inputs must be created for the `pso()` function as described below:


```{r pso2}
par <- rep(NA, 2)
fn <- function(x){return(sum(abs(x)))}
lower <- -10
upper <- 10
control = list(
  s = 10, # swarm size
  c.p = 0.5, # inherit best
  c.g = 0.5, # global best
  maxiter = 100, # iterations
  w0 = 1.2, # starting inertia weight
  wN = 0, # ending inertia weight
  save_traces = F # save more information
)
```


Now it is time to initialize the random positions `X`, their fitness `X_fit` and their random velocities `V` with the created function `mrunif()` which produces a matrix of uniformly distributed random numbers between `lower` and `upper`:


```{r pso3}
set.seed(0)
X <- mrunif(
  nr = length(par), nc=control$s, lower=lower, upper=upper
)
if(all(!is.na(par))){
  X[, 1] <- par
}
X_fit <- apply(X, 2, fn)
V <- mrunif(
  nr = length(par), nc=control$s, 
  lower=-(upper-lower), upper=(upper-lower)
)/10
```


The velocities are compressed by a factor of 10 to start with a maximum movement of one tenth of the space in each axis. The personal best positions `P` are the same as `X` and the global best position is the position with the smallest fitness:


```{r pso4}
P <- X
P_fit <- X_fit
p_g <- P[, which.min(P_fit)]
p_g_fit <- min(P_fit)
```


The required data structure is available and the optimization can start with the calculation of the new velocities and the transformation of the old positions. When particles have left the valid space of an axis, they are pushed back to the edge and the velocity on this axis is set to zero. Then the fitness is calculated and the personal best and global best positions are saved if they have improved.


```{r pso5}
trace_data <- NULL
for(i in 1:control$maxiter){
  # move particles
  V <- 
    (control$w0-(control$w0-control$wN)*i/control$maxiter) * V + 
      control$c.p * t(runif(ncol(X)) * t(P-X)) +
      control$c.g * t(runif(ncol(X)) * t(p_g-X))
  X <- X + V
  
  # set velocity to zeros if not in valid space
  V[X > upper] <- 0
  V[X < lower] <- 0
  
  # move into valid space
  X[X > upper] <- upper
  X[X < lower] <- lower
  
  # evaluate objective function
  X_fit <- apply(X, 2, fn)
  
  # save new personal best
  P[, P_fit > X_fit] <- X[, P_fit > X_fit]
  P_fit[P_fit > X_fit] <- X_fit[P_fit > X_fit]
  
  # save new global best
  if(any(P_fit < p_g_fit)){
    p_g <- P[, which.min(P_fit)]
    p_g_fit <- min(P_fit)
  }
}
```


The global minimum is located at $[0, 0]$ which has a fitness of $0$ and the best position found from the PSO after $100$ iterations is located at `r paste0("[",paste0(round(p_g, 12), collapse=", "), "]")` and has a fitness of `r round(p_g_fit, 12)`. 


```{r pso6, include = knitr::is_html_output(), class.source="code_fold_it_collapsed"}
# load default PSO
source("R/PSO_functions.R")
```




## Animation 2-Dimensional
This section provides insights into the behavior of the PSO by visualizing multiple iterations in a GIF. The GIF works in Adobe Acrobat DC or in the Markdown/HTML version of this thesis. The amazing animation template and the objective function is inspired by [@Rtic2021]. The PSO core from the above chapter was used to complete the `pso()` function and is tested here with seed 0. The objective is to minimize the following function ($f:\mathbb{R}^2 \rightarrow \mathbb{R}$):

$$
f(x, y) = -20\cdot e^{-0.2 \cdot \sqrt{0.5 \cdot ((x-1)^2 + (y-1)^2)}} \ - e^{0.5 \cdot ( cos(2\cdot \pi \cdot x) + cos(2\cdot \pi \cdot y))} + e + 20
$$

The following code runs the PSO and tries to minimize the objective function:


```{r gifcreate}
set.seed(0)

f <- function(pos){
  -20 * exp(-0.2 * sqrt(0.5 *((pos[1]-1)^2 + (pos[2]-1)^2))) - 
  exp(0.5*(cos(2*pi*pos[1]) + cos(2*pi*pos[2]))) + 
  exp(1) + 20
}

res <- pso(
  par = rep(NA, 2),
  fn = f,
  lower = -10,
  upper = 10,
  control = list(
    s = 10,
    maxiter = 30,
    w0 = 1.2,
    save_traces = T
  )
)
```


The function `f` has many local minima and a global minima at $(1,1)$ with the value $0$. The background color scale ranges from 0 as red to 20 as purple. The PSO has 10 particles, iterated 30 times with an inertia weight decreasing from 0.8 to 0. The iterations are visualized in the following GIF:


```{r gifanimate, echo=F}
# grid <- expand.grid(seq(-10, 10, length.out = 100), seq(-10, 10, length.out = 100), stringsAsFactors = F)
# grid$z <- apply(grid, 1, f)
# 
# 
# background <- ggplot() +
#   geom_contour_filled(data = grid, aes(x = Var1, y = Var2, z = z), color = "black", alpha = 0.5) +
#   scale_fill_brewer(palette = "Spectral") +
#   theme(axis.line=element_blank(),
#       axis.text.x=element_blank(),
#       axis.text.y=element_blank(),
#       axis.ticks=element_blank(),
#       axis.title.x=element_blank(),
#       axis.title.y=element_blank(),
#       legend.position="none",
#       panel.background=element_blank(),
#       panel.border=element_blank(),
#       panel.grid.major=element_blank(),
#       panel.grid.minor=element_blank(),
#       plot.background=element_blank())
# ggsave(background, filename = "gifs/pso_2dim/background.jpg", scale = 1, dpi=150)
# 
# 
# anim <- ggplot(res$trace_data) +
#   background_image(jpeg::readJPEG("gifs/pso_2dim/background.jpg")) +
#   geom_point(aes(X1, X2)) +
#   xlim(-10, 10) +
#   ylim(-10, 10) +
#   labs(x = "X", y = "Y") +
#   transition_time(iter) +
#   ease_aes("linear")
# 
# 
# 
# if(!knitr::is_latex_output()){
#   temp <- sapply(list.files('gifs/pso_2dim/', full.names = T), file.remove)
#   suppressMessages(animate(anim, renderer = file_renderer('gifs/pso_2dim/'), device = "jpeg", nframes=100, fps=10, duration=10,  start_pause = 10))
#   images <- list.files('gifs/pso_2dim/')
#   for(i in 1:length(images)){
#     file.rename(
#       paste0('gifs/pso_2dim/',images[i]), 
#       paste0("gifs/pso_2dim/gganim_plot", as.numeric(gsub(".jpg", "", gsub(pattern = "gganim_plot","", images[i])))+10, ".jpg")
#     )
#   }
#   for(i in 10:1){
#     file.copy(
#       from = 'gifs/pso_2dim/gganim_plot11.jpg',
#       to = paste0("gifs/pso_2dim/gganim_plot", i, ".jpg")
#     )
#   }
#   anim
# }

```
```{=latex}
\begin{center}
\animategraphics[loop, width=10cm]{10}{./gifs/pso_2dim/gganim_plot}{1}{80}
\begin{figure}[!h]
\caption{Visualization of the behavior of the standard PSO in a GIF.}
\end{figure}
\end{center}
```


## Animation 2-Dimensional App
To gain an even better understanding of the behavior of a PSO, a WebApp was developed that allows the user to minimize arbitrary two-dimensional functions with constraints. Three variants of the PSO were implemented, which will be analyzed in detail in the later chapters of this thesis. The app can also be used to study the effect of hyperparameters on the behavior of the PSO in more detail. Within the app it is possible to display each step of the iterations and this even with all the direction vectors that generate the resulting motion of each particle. The app is hosted at [@PSOApp] and the code for it is also freely available at [@GitPSO]. The hosted app may be used for educational purposes and using, copying, modifying, and sharing the code is permitted without restriction.


## Simple Constraint Handling
The simplest method for dealing with constraints is the penalty method, which takes into account the intensity of constraint breaks by increasing the objective value of a minimization problem. The two common problems studied in the last two chapters are quadratic problems with the same structure of constraints. This can be used to create a generic constraint handling function for these particular QP's. Both problems must satisfy the following equation:

$$
  A^T \times x  \geq b_0
$$

To calculate a value for the intensity of constraint breaks, the above inequality is subtracted by $b_0$ and the left-hand side is defined as follows:

$$
  c := A^T \times x - b_0
$$

All negative elements in the vector $c$ represent constraint breaks that are squared and summed to extract a value that describes the intensity of constraint breaks like follows:

$$
  c_{break} = \sum p(c_i)^2
$$

with

$$
 p(x) =   \begin{cases}
  0 &\text{ if }x \geq 0\\
  x &\text{ if }x < 0
  \end{cases}
$$

By following the name conventions of `solve.QP`, a list named `mat` is created in the parent environment, that contains the necessary inputs. The generic R function to calculate the constraint breaks can be defined as follows:


```{r}
calc_const <- function(x){
  const <- t(mat$Amat) %*% x - mat$bvec
  sum(pmin(0, const)^2)
}
```


In contrast to the `solve.QP`, it's difficult for the PSO to find a feasible point, if equality constraints are used, which is why the equality constraint $\textstyle\sum w_i = 1$ is reduced to $0.99 \leq \textstyle\sum w_i$ and $\textstyle\sum w_i \leq 1$. 

The new objective function `fn()` consists of two parts. The first part is to evaluate the unconstrained objective of the QP with the following function:


```{r}
calc_fit <- function(x){
  0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x
}
```


The second part is the function `calc_const()`. Since breaking constraints is much worse than losing fitness, it must have a higher intensity (e.g. 10) which must be fine-tuned. This results in the final `fn()` function composition:


```{r}
fn <- function(x){
  fitness <- calc_fit(x)
  constraints <- calc_const(x)
  return(fitness + 10 * constraints)
}
```


This approach to dealing with constraints is called the penalization method and is definitely the most straightforward approach. Its disadvantage is the fact that the PSO has to find a balance between the violation of constraints and the goal. As explained in [@InSi2008], there are three other constraint handling methods, but the results show that none of them is superior. The treatment of constraints should be chosen appropriately for the given problem. For example, it may be useful to use the feasibility preservation technique to obtain a solution that is guaranteed not to break any constraints. The disadvantages here are longer computation time and less exploration of particles, since only feasible solutions can be stored as personal or global best solutions.


## Convergence Analysis of the Standard PSO
This section summarizes the mathematical convergence analysis of the standard PSO with constant inertia weight $w$ performed in [@FbEn2010], whose main goal is to prove whether the PSO converges to a local or even a global minimum. In this section, the results from the sources are presented in a simplified form so that the complete scope can be understood. For this purpose, mathematical principles are presented in a simplified way and not proven, since otherwise it would exceed the scope of this thesis. It is recommended to look at the exact proofs in the mentioned sources to get a deeper understanding of it.

First, we show whether the PSO satisfies the *algorithm condition* and the *convergence condition (for local search)* to be classified as a local search algorithm, i.e., that the PSO is guaranteed to converge to at least one local minimum. Formally, this is defined in the following theorem:


::: {.theorem name="Local search algorithm"}
Assume that $f$ is a measurable function, $S$ is a measurable subset of $\mathbb{R}^n$ and both the algorithm condition and the convergence condition (for local search) are satisfied. Let $\{x_i\}^{\infty}_{i=0}$ be a sequence generated by the algorithm, D. Then,

$$
  \lim_{i\rightarrow \infty} \ P(x_i \in R_{l,\epsilon}) = 1
$$

:::


and the optimality region $R_{l,\epsilon}$ is defined as

$$
 R_{l,\epsilon} = \{z\in S \ | f(z) < \psi + \epsilon\}
$$

where $\psi$ denotes the essential infimum of $f$ on $S$, and $\epsilon > 0$. The optimality region can be interpreted as a union of arbitrarily small bounded subsets of $S$ containing a local minimum. This is necessary because each point in the search space $S$ has a probability measure of zero to be randomly generated. For a precise mathematical definition of the optimality region $R_{l,\epsilon}$ see [@Fdbe2006].

We can now start analyzing the *algorithm condition*, which is defined as follows:

**Algorithm condition**: The mapping $D: S \times \mathbb{R}^n\rightarrow S$ should satisfy $f(D(z, \xi)) \leq f(z)$ and if $\xi \in S$, then $f(D(z, \xi)) \leq f(\xi)$.

That is, the *algorithm condition* is satisfied if the algorithm has a mapping $D$ that compares two positions and returns the position with the lowest objective value that is also in the domain of definition. In terms of the PSO, we are concerned with the behavior when the global best position $z := p_{g}$ is changed. If a new personal best position $\xi:=p_{p}$ is found, it is guaranteed to be in the definition space, since all calculated positions are pushed back to their edge if they are outside the definition space. Then, the PSO compares the objective value of $\xi$ with the objective value of $z$ and stores the position with the lowest objective value as the global best position. Thus, the PSO satisfies the *algorithm condition*. 

The next condition focuses on the convergence behavior of the PSO, which must ensure that the swarm converges to a fixed point. In [@FbEn2010], results were referenced from [@RiPo2007], which analyzed the convergence property of a deterministic PSO, i.e., when the uniformly random numbers are replaced by their upper bounds. Subsequently, the results were verified by simulations of the stochastic standard PSO. This work was subsequently extended by [@Mjly2006] to deal directly with the stochastic version of the standard PSO. 

In [@Mjly2006], three properties are described for the behavior of the PSO. First, the trajectory of each particle $d$ is described as a sequence of random variables $\{\pmb{X}^d_i\}$, with particle positions $\pmb{X}^d_i$ at iteration $i$. Property 1 is satisfied if the expected value of particle positions $\pmb{X}^d_i$ converges to a fixed point for each particle ($\lim_{i\rightarrow \infty} E[\pmb{X}^d_i] = p^d \ \forall d$). Property 2 is satisfied if the variance of the positions for each particle tends to zero ($\lim_{i\rightarrow \infty} Var[\pmb{X}^d_i] = 0 \ \forall d$). Property 3 is satisfied if the entire particle swarm converges to a fixed point in the mean square, i.e., all particle positions converge to a single point $\hat{p}$, which can be summarized as $\lim_{i\rightarrow \infty} E[\pmb{X}_i^d-\hat{p}]^2=0 \ \forall d$. 

Properties 1-3 depend on the choice of $c_p$, $c_g$ and $w$, which can be found in [@Mjly2006]. The proofs and deeper explanations of the constraints on parameters are beyond the scope of this thesis. In the following, the regions for each property are visualized and the blue region is denoted as the convergent parameter region with bounds $c_p$=$c_g$=$c>0$ and $0<w<1$:


```{r convergenceregion, echo=F, fig.cap="Relationship between $w$ and $c$ when $c_p$=$c_g$=$c$ to distinguish between different convergence behaviors. The black area shows the convergence condition for the sequence of expected positions satisfying property 1. The cyan area shows the convergence condition for the sequence of expected positions and the variances tending to zero, which satisfies properties 1 and 2. And the blue area shows the convergence condition for the sequence of expected positions with the variances tending to zero and the entire swarm converging to a single point, which satisfies properties 1, 2, and 3. This is a replication of the visualization from [Jiang et al., 2007]"}



df <- expand.grid(w=seq(from=0, to=1, length.out=1000), c=seq(from=0, to=4, length.out=1000))

df <- df %>% 
  mutate(
    black = 
      c > 0 &
      w > 0 &
      2*c < 4*(1+w),
    blue = 
       w > 0 & 
       w < 1 &
       c > 0 &
       (2*c)<(4*(1+w)) &  
       (-2*c*w^2+(2/6*c^2+1/2*c^2)*w+2*c-2/3*c^2-1/2*c^2) > 0,
    dark_blue = 
       w > 0 & 
       w < 1 &
       c > 0 &
       (2*c)<(4*(1+w)) &  
       (-2*c*w^2+(2/6*c^2+1/2*c^2)*w+2*c-2/3*c^2-1/2*c^2) > 0 &
       (-2*c*w^2+(2/6*c^2+1/2*c^2)*w+2*c-2/3*c^2-1/2*c^2) < (c^2*(1+w)/6),
    
  )

grid <- df %>% select(black, c, w) %>% spread(., key = w, value = black) %>% column_to_rownames("c") %>% as.matrix() + df %>% select(blue, c, w) %>% spread(., key = w, value = blue) %>% column_to_rownames("c") %>% as.matrix() + df %>% select(dark_blue, c, w) %>% spread(., key = w, value = dark_blue) %>% column_to_rownames("c") %>% as.matrix()

plot_ly(z = grid*1, type = "heatmap", x = colnames(grid), y=rownames(grid), colors = colorRamp(c("white", "black", "cyan", "blue")), showscale = FALSE) %>% 
  layout(xaxis=list(title="w"), yaxis=list(title="c"), margin=list(r=60)) %>% 
  config(displayModeBar = FALSE) %>% 
  html_save()

```


In the online version of this thesis, the diagram can be displayed with additional information as a mouse-hover, which facilitates the precise classification of a parameter pair.

Back to the convergence behavior of the PSO analyzed in [@FbEn2010], which uses parameters $w$, $c_p$ and $c_g$ that are located in the convergent parameter region. This results in a standard PSO that converges with all particles in a single point $\hat{p}$. The PSO is guaranteed to reach at least a local minimum if, in addition to the *algorithm condition*, the following condition is also satisfied:

Returning to the convergence behavior of the PSO analyzed in [@FbEn2010], which uses parameters $w$, $c_p$, and $c_g$ that lie in the convergent parameter region. This leads to a standard PSO that converges with all particles in a single point $\hat{p}$. The PSO is guaranteed to reach at least a local minimum if, in addition to the *algorithm condition*, the following condition is also satisfied:

**Convergence condition (for local search):** Sufficient condition for convergence to at least a local minimum: For any $x_i\in S$ there exists a $\gamma > 0$ and an $0<\eta\leq1$ such that

$$
  \mu_i(\text{dist}(x_{i+1}, R_{l,\epsilon}) \leq \text{dist}(x_{i}, R_{l,\epsilon})-\gamma \ \text{  or  } \  x_i \in R_{l,\epsilon} ) \geq \eta
$$

with a probability measure $\mu_i$ and a distance measure $\text{dist}()$.


Simply put, the *convergence condition (for local search)* is satisfied if the PSO has a zero probability of decreasing the distance to the optimality region in each iteration. Unfortunately, this is not the case, as can be seen in a simple example. Suppose the PSO is to minimize a 2-dimensional objective function $f$ with only two particles and the initial positions are $x_1=(k_1, k_2)$, $x_2=(k_1, k_2) + a_1 \cdot (1, 0)$ and the initial velocities are $v_1=a_2 \cdot (1, 0)$ and $v_2=a_3 \cdot (1, 0)$ with constants $k_1, k_2, a_1, a_2$, and $a_3$. It follows that the personal and global best positions have $k_2$ in the second coordinate, resulting in a zero in the second coordinate of the velocity update in all iterations. Therefore, the coordinate $k_2$ is not guaranteed to lead to the optimality region and the PSO cannot improve in the second coordinate, which contradicts the *convergence condition (for local search)* and it follows that the PSO is not a local search algorithm.

The possibility of this premature stagnation in a coordinate decreases significantly with increasing particle number, which is why it is very unlikely in practice. In order for the PSO to still be classified as a local search algorithm, a variant of the PSO was developed in [@FbEn2010], called the guaranteed convergence PSO (GCPSO). In this variant, it is guaranteed that if no improvement occurs, it is at least possible to randomly shift the position of each particle in each coordinate by the machine precision. Therefore, the GCPSO is classified as a local search algorithm. 

To extend the GCPSO to a global search algorithm, it must satisfy the following theorem:


::: {.theorem name="Global search algorithm"}
Assume that $f$ is a measurable function, $S$ is a measurable subset of $\mathbb{R}^n$ and both the algorithm condition and the convergence condition (for global search) are satisfied. If $\{x_i\}^{\infty}_{i=0}$ is a sequence generated by the algorithm, D, then

$$
  \lim_{i\rightarrow \infty} \ P(x_i \in R_{g,\epsilon}) = 1
$$

:::


and $R_{g,\epsilon}$ is to be interpreted as the arbitrarily small bounded subset of $S$ containing the global minimum. Moreover, the *convergence condition (for global search)* is defined as follows:

**Convergence condition (for global search):** Sufficient condition for convergence to a global minimum: For any (Borel) subset $A$ of $S$ with $m(A)>0$,

$$
  \prod_{i=0}^\infty (1-\mu_i(A)) = 0
$$
where $\mu_i(A)$ is the probability of $A$ being generated by $\mu_i$.

To summarize and simplify, the algorithm is classified as a global search algorithm if the *algorithm condition* is satisfied and the algorithm has zero probability of repeatedly missing the region $R_{g,\epsilon}$

This behavior of the GCPSO can be achieved by making very small changes to the algorithm. For example, by introducing a particle that is randomly generated every $k$ iterations. Another approach is to restart the PSO when the majority of particles are in a small region. Other approaches and their advantages are discussed in [@FbEn2010].


In this theoretical approach, the behavior of the PSO is analyzed with increasing iterations to infinity. In practice, the PSO is often used for complex problems, and usually a local minimum with a Pareto-optimal objective value is sufficient for the purpose, since a fast solution is usually preferred. To achieve faster convergence to Pareto-optimal minima, the decreasing inertia weight $w$ is used, and to increase the probability of finding the global optimum, the PSO is restarted after the maximum number of iterations. This is often done until a certain time or number of restarts is reached.






## Example MVP
This example uses the `solve.QP` approach from section \@ref(exampleanalyticalmvp) with ten assets as the benchmark. Briefly, the goal is to create an MVP from ten of the largest U.S. stocks between 2018-01-01 and 2019-12-31 for each possible $\lambda$. The PSO has 300 particles and 200 iterations for each lambda. The starting position is the equally weighted vector $v$ with $\textstyle\sum v_i=1$. The main characteristics of all portfolios created with the `solve.QP` compared to the PSO are shown below:


```{r pso7, echo = knitr::is_html_output(), class.source="code_fold_it_collapsed", fig.cap = "Comparison of the MVP's generated with solve.QP and the PSO. The gray lines show the difference of the solutions of both approaches for each lambda"}
set.seed(0)

returns_raw <- buffer(
  get_yf(
    tickers = c("IBM", "GOOG", "AAPL", "MSFT", "AMZN", 
                "NVDA", "JPM", "META", "V", "WMT"), 
    from = "2018-01-01", 
    to = "2019-12-31"
  )$returns, 
  "AS_10_assets"
)

# re-arrange: low var first
vars <- sapply(returns_raw, var)
returns_raw <- returns_raw[, order(vars, decreasing = F)]

mvp_QP <- function(returns, lambda){
  tc <- tryCatch({
    mu <- ret_to_geomeanret(returns)

    cov <- as.matrix(nearPD(cov(returns))$mat)

    mat <- list(
      Dmat = lambda * cov,
      dvec = (1-lambda) * mu,
      Amat = t(rbind(
        -rep(1, ncol(returns)), # sum w <= 1
        rep(1, ncol(returns)), # sum w >= 0.99
        diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only
      )),
      bvec = c(
        -1, # sum w <= 1
        0.99, # sum w >= 0.99
        rep(0, ncol(returns)) # long only
      ),
      meq = 0
    )
  
    qp <- solve.QP(
      Dmat = mat$Dmat, dvec = mat$dvec, 
      Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq
    )
    
    res <- list(
      "mu" = mu %*% qp$solution,
      "var" = t(qp$solution) %*% cov %*% qp$solution,
      "composition" = setNames(qp$solution, colnames(returns))
    )
    TRUE
  }, error = function(e){FALSE})
  

  if(tc){
    return(res)
  }else{
    return(list(
      "mu" = NA,
      "var" = NA,
      "composition" = NA
    ))
  }
}


mvp_PSO <- function(returns, lambda, silent = T){
  tc <- tryCatch({
    mu <- ret_to_geomeanret(returns)

    cov <- cov(returns)

    mat <- list(
      Dmat = lambda * cov,
      dvec = (1-lambda) * mu,
      Amat = t(rbind(
        -rep(1, ncol(returns)), # sum w <= 1
        rep(1, ncol(returns)), # sum w >= 0.99
        diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only
      )),
      bvec = c(
        -1, # sum w <= 1
        0.99, # sum w >= 0.99
        rep(0, ncol(returns)) # long only
      ),
      meq = 0
    )
  
    calc_fit <- function(x){
      0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x
    }
    calc_const <- function(x){
      const <- t(mat$Amat) %*% x - mat$bvec
      sum(pmin(0, const)^2)
    }
    pso_res <- pso(
      par = rep(1/ncol(returns), ncol(returns)),
      fn = function(x){
        fitness <- calc_fit(x)
        constraints <- calc_const(x)
        return(fitness + 10 * constraints)
      },
      lower = 0,
      upper = 1,
      control = list(
        s = 300, # swarm size
        c.p = 0.5, # inherit best
        c.g = 0.5, # global best
        maxiter = 200, # iterations
        w0 = 1.2, # starting inertia weight
        wN = 0, # ending inertia weight
        save_traces = F, # save more information
        save_fit = F
      )
    )
    if(!silent){
      p0("constraint: ", sum(calc_const(pso_res$solution)))
      p0("fitness: ", calc_fit(pso_res$solution))
    }
    
    res <- list(
      "mu" = mu %*% pso_res$solution,
      "var" = t(pso_res$solution) %*% cov %*% pso_res$solution,
      "composition" = setNames(pso_res$solution, colnames(returns)),
      "fit" = calc_fit(pso_res$solution),
      "constraint" = sum(calc_const(pso_res$solution))
    )
    TRUE
  }, error = function(e){FALSE})
  

  if(tc){
    return(res)
  }else{
    return(list(
      "mu" = NA,
      "var" = NA,
      "composition" = NA
    ))
  }
}


df <- NULL
runs <- 100
for(i in 0:round((runs-1)*0.4)){
  lambda <- 1-i/runs
  temp <- mvp_QP(returns = returns_raw, lambda = lambda)
  df <- rbind(df, data.frame("type"="QP_MVP", "lambda"=lambda, "mu"=temp$mu, "var"=temp$var, "constraint"=0))
  
  temp <- mvp_PSO(returns = returns_raw, lambda = lambda)
  df <- rbind(df, data.frame("type"="PSO_MVP", "lambda"=lambda, "mu"=temp$mu, "var"=temp$var, "constraint"=temp$constraint))
}

df$sd = sqrt(df$var)



df_qp <- df[df$type=="QP_MVP" & df$lambda %in% seq(1,0.8,-0.1),]
df_diff <- data.frame(
  "mu_pso" = df[df$type=="PSO_MVP",]$mu,
  "sd_pso" = df[df$type=="PSO_MVP",]$sd,
  "mu_qp" = df[df$type=="QP_MVP",]$mu,
  "sd_qp" = df[df$type=="QP_MVP",]$sd
)

shapes <- list()
for(i in 1:nrow(df_diff)){
  shapes[[i]] <- list(
    type = "line", 
    y0 = df_diff[i,]$mu_pso, 
    y1 = df_diff[i,]$mu_qp, 
    yref = "y",
    xref = "x",
    x0 = df_diff[i,]$sd_pso, 
    x1 = df_diff[i,]$sd_qp, 
    line = list(color = "lightgrey"),
    layer='below'
  )
}


plot_ly(
  data = df, 
  x=~sd, 
  y=~mu, 
  name=~type, 
  mode="markers", 
  type = 'scatter', 
  color = ~type, 
  colors = c("green", "red")
  ) %>% 
  add_annotations(
    data=df_qp,   
    x=~sd, 
    y=~mu, 
    text = ~paste0("lambda: ",lambda),
    ay = -30,
    ax = -30
  ) %>% 
  layout(
    xaxis=list(title = "sigma", range=c(0.5*min(df$sd), 1.2*max(df[df$type=="QP_MVP",]$sd)), showgrid = FALSE),
    yaxis=list(range=c(0.5*min(df$mu), 1.2*max(df[df$type=="QP_MVP",]$mu)), showgrid = FALSE),
    shapes = shapes,
    legend = list(x = 0.1, y = 0.9)
  ) %>% 
  html_save()
```


The corresponding portfolios for each $\lambda$ are connected with a grey line to visualize the error of the PSO. It turns out that it is possible to solve MVP problems with a PSO approach. It is noticable that some PSO runs were not able to reach the global minimum and thus show a deviation from the `solve.QP` approach, which can often be fixed by repeated runs. 

## Example: ITP-MSTE
The same ITP-MSTE solved with `solve.QP` in \@ref(exampleitpsolveqp) is used as the benchmark for the PSO. In summary, the goal is to create a portfolio that minimizes the mean square error of the returns of itself and the SP500TR between 2018-01-01 and 2019-12-31. The pool of assets includes all assets that are present in 2019-12-31 and have no missing values. The constraints are long only and the weights should sum to one. The parameters for the PSO are a swarm size of 100, 100 iterations, the inertia weight starts at $1.2$ and decreases to zero, the upper bound is $0.05$, and a starting position is the equally weighted vector $v$ with $\textstyle\sum v_i=1$. The PSO was run ten times, and the aggregated best and mean runs are compared to the `solve.QP` approach for seed 0 in the table below:


```{r pso8, echo = knitr::is_html_output(), class.source="code_fold_it_collapsed", fig.cap = "Comparison of solving ITP-MSTE with solve.QP and the PSO"}
set.seed(0)
 
from <- "2018-01-01"
to <- "2019-12-31"

spx_composition <- buffer(
  get_spx_composition(),
  "AS_spx_composition"
)


pool_returns_raw <- buffer(
  get_yf(
    tickers = spx_composition %>% 
      filter(Date<=to) %>% 
      filter(Date==max(Date)) %>% 
      pull(Ticker), 
    from = from, 
    to = to
  )$returns, 
  "AS_sp500_assets"
)
pool_returns_raw <- 
  pool_returns_raw[, colSums(is.na(pool_returns_raw))==0]


bm_returns <- buffer(
  get_yf(tickers = "^SP500TR", from = from, to = to)$returns, 
  "AS_sp500tr"
) %>% setNames(., "SP500TR")




itp_QP <- function(pool_returns, bm_returns){

  mat <- list(
    Dmat = t(pool_returns) %*% pool_returns,
    dvec = t(pool_returns) %*% bm_returns,
    Amat = t(rbind(
      -rep(1, ncol(pool_returns)), # sum w <= 1
      rep(1, ncol(pool_returns)), # sum w >= 0.99
      diag(1, 
           nrow=ncol(pool_returns), 
           ncol=ncol(pool_returns)) # long only
    )),
    bvec = c(
      -1, # sum w <= 1
      0.99, # sum w >= 0.99
      rep(0, ncol(pool_returns)) # long only
    ),
    meq = 0
  )
  
  qp <- solve.QP(
    Dmat = mat$Dmat, dvec = mat$dvec, 
    Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq
  )

  
  res <- list(
    "value" = qp$value,
    "var" = as.numeric(
      var(pool_returns %*% qp$solution - bm_returns)),
    "solution" = setNames(qp$solution, colnames(pool_returns))
  )
}


itp_PSO <- function(pool_returns, bm_returns, silent = T){
  mat <- list(
    Dmat = t(pool_returns) %*% pool_returns,
    dvec = t(pool_returns) %*% bm_returns,
    Amat = t(rbind(
      -rep(1, ncol(pool_returns)), # sum w <= 1
      rep(1, ncol(pool_returns)), # sum w >= 0.99
      diag(1, 
           nrow=ncol(pool_returns), 
           ncol=ncol(pool_returns)) # long only
    )),
    bvec = c(
      -1, # sum w <= 1
      0.99, # sum w >= 0.99
      rep(0, ncol(pool_returns)) # long only
    ),
    meq = 0
  )
  
  calc_fit <- function(x){
    as.numeric(0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x)
  }
  calc_const <- function(x){
    const <- t(mat$Amat) %*% x - mat$bvec
    sum(pmin(0, const)^2)
  }
  pso_res <- pso(
    par = rep(1/ncol(pool_returns), ncol(pool_returns)),
    fn = function(x){
      fitness <- calc_fit(x)
      constraints <- calc_const(x)
      return(fitness+10*constraints)
    },
    lower = 0,
    upper = 0.05,
    control = list(
      s = 200, # swarm size
      c.p = 0.5, # inherit best
      c.g = 0.5, # global best
      maxiter = 100, # iterations
      w0 = 1.2, # starting inertia weight
      wN = 0, # ending inertia weight
      save_traces = F # save more information
    )
  )
  if(!silent){
    p0("constraint: ", sum(calc_const(pso_res$solution)))
    p0("fitness: ", calc_fit(pso_res$solution))
  }
  
  res <- list(
    "composition" = setNames(pso_res$solution, colnames(pool_returns)),
    "fit" = calc_fit(pso_res$solution),
    "constraint" = calc_const(pso_res$solution),
    "var" = as.numeric(
      var(pool_returns %*% pso_res$solution - bm_returns))
  )
  
  return(res)
}


df <- NULL
time <- system.time(
  temp_qp <- itp_QP(pool_returns_raw, bm_returns)
)
df <- data.frame("type"="ITP-MSTE_QP", "var"=temp_qp$var, "fitness"=temp_qp$value, "constraint"=0, "time"=time[3])
for(i in 1:10){
  time <- system.time(
    temp_pso <- itp_PSO(pool_returns = pool_returns_raw, bm_returns)
  )
  df <- rbind(
    df, 
    data.frame(
      "type"="ITP-MSTE_PSO", 
      "var"=temp_pso$var, 
      "fitness"=temp_pso$fit, 
      "constraint"=temp_pso$constraint, 
      "time"=time[3]
    )
  )
  
  
}
df$sd <- sqrt(df$var)

df_summary <- rbind(
  df %>% filter(type == "ITP-MSTE_QP"),
  df %>% filter(type == "ITP-MSTE_PSO") %>% filter(fitness == min(fitness)) %>% mutate(type = "ITP-MSTE_PSO_best"),
  df %>% filter(type == "ITP-MSTE_PSO") %>% group_by(type) %>% summarise_all(., mean) %>% mutate(type = "ITP-MSTE_PSO_mean")
)
rownames(df_summary) <- NULL
df_summary$var <- round(df_summary$var, 12)
df_summary$sd <- round(df_summary$sd, 6)
df_summary$fitness <- round(df_summary$fitness, 7)
df_summary$constraint <- round(df_summary$constraint, 18)
df_summary$time <- round(df_summary$time, 1)

reactable(
  df_summary %>% select(type, sd, var, fitness, constraint, time),
  wrap = FALSE,
  compact = T,
  columns = list(
    type = colDef(width=140),
    var = colDef(format = colFormat(digits=9), show =F),
    sd = colDef(format = colFormat(digits=5), width=75),
    constraint = colDef(name = "constraint break", format = colFormat(digits=9)),
    time = colDef(width=75)
  ),
  style = list(fontFamily="Computer Modern, sans-serif", fontSize=13)
) %>% 
  html_save(., expand = c(-40,-20,-60,-20))
```



It can be seen that in all PSO runs, sufficient fitness was achieved with negligible constraint breaks, but much more computation time was required.

## Pros and Cons for Continuous Problems
A PSO approach has advantages and disadvantages, since on the one hand any problem can theoretically be solved, but it cannot be guaranteed that the solution is also optimal. In addition, the calculations take much longer than with the `solve.QP` approach, which raises the question why a PSO approach should have any benefit at all. This is exactly the case, if the solution of the problem is no longer possible by the `solve.QP` alone, as it is for example the case with mixed-integer-quadratic-problems. In these types of problems, the condition for the variable of interest $x$ is to be a integer vector. These kind of problems could be solved by the `solve.QP` approach only continuously and then rounded. However, this rounding error can become arbitrarily large, which is why the chances of the PSO approach to achieve a better solution are greater than with the `solve.QP` approach.


## Discrete Problems
A continuous solution for a portfolio is not sufficient for practical purposes, since usually only integer amounts of assets can be purchased. It's even worse if lot sizes are needed, because these can only be bought in minimum denomination of e.g. ten thousand. Lot sizes are often used in fixed income products. The biggest drawbacks of rounding a continuous solution are the disregarding of conditions and the difference in the objective value, which often can't reach the new optimum. A solution with broken conditions is not acceptable in practice and a `solve.QP` approach only produces one solution, which is why its insecure to hope for a sufficient solution after rounding. The PSO doesn't have these drawbacks and can be easily used for discrete problems by rounding the input of the objective function `fn()`. In a portfolio with net asset value (`nav`) consisting of only American stocks with weights $w_i$ and closing prices $p_i$ can be discretized to $w_i^d$ by the following formula:

$$
  w_i^d =\text{round}(w_i \cdot \frac{\text{nav}}{p_i})\cdot \frac{p_i}{\text{nav}}
$$

## Example: Discrete ITP-MSTE
This example analyses the error of rounding a solution with the `solve.QP` approach and compares it to a discrete PSO. A second discrete PSO is added, that takes the continuous solution of the `solve.QP` and uses it as starting position of one particle. The ITP-MSTE focuses on replicating the SP500TR with its top 100 assets derived from the example with discarding in section \@ref(exampleitpsolveqp) and tries to construct a portfolio with the constraints long only, $0.99 \leq \textstyle\sum w_i \leq 1$ and $\text{nav} = 10000$ in the time frame from 2018-01-01 to 2019-12-31. The used prices are closing prices and both PSO's have 200 particles and 200 iterations. The results can be observed in the table below:


```{r pso9, echo = knitr::is_html_output(), class.source="code_fold_it_collapsed", fig.cap="Comparison of solving dicrete ITP-MSTE with solve.QP with rounding and the PSO"}
set.seed(0)

nav <- 10000
 
from <- "2018-01-01"
to <- "2019-12-31"

spx_composition <- buffer(
  get_spx_composition(),
  "AS_spx_composition"
)


pool_data <- buffer(
  get_yf(
    tickers = spx_composition %>% 
      filter(Date<=to) %>% 
      filter(Date==max(Date)) %>% 
      pull(Ticker), 
    from = from, 
    to = to
  ), 
  "AS_sp500_asset_data"
)

load("data/assets_pool_100.rdata")

pool_data$returns <- pool_data$returns[, assets_pool_100]
pool_data$prices <- pool_data$prices[, assets_pool_100]


bm_returns <- buffer(
  get_yf(tickers = "^SP500TR", from = from, to = to)$returns, 
  "AS_sp500tr"
) %>% setNames(., "SP500TR")



pool_returns <- pool_data$returns
mat <- list(
  Dmat = t(pool_returns) %*% pool_returns,
  dvec = t(pool_returns) %*% bm_returns,
  Amat = t(rbind(
    -rep(1, ncol(pool_returns)), # sum w <= 1
    rep(1, ncol(pool_returns)), # sum w >= 0.99
    diag(1, 
         nrow=ncol(pool_returns), 
         ncol=ncol(pool_returns)) # long only
  )),
  bvec = c(
    -1, # sum w <= 1
    0.99, # sum w >= 0.99
    rep(0, ncol(pool_returns)) # long only
  ),
  meq = 0
)

calc_fit <- function(x){
  as.numeric(0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x)
}
calc_const <- function(x){
  const <- t(mat$Amat) %*% x - mat$bvec
  sum(pmin(0, const)^2)
}

# Default solve.QP
time_qp <- system.time({
  res_qp <- itp_QP(pool_data$returns, bm_returns)
  prices <- last(pool_data$prices)
  res_qp_discrete <- setNames(as.vector(round(res_qp$solution*nav/prices)*prices/nav), names(res_qp$solution))
})
res_qp_discrete_fit <- calc_fit(res_qp_discrete)
res_qp_discrete_const <- calc_const(res_qp_discrete)
res_qp_discrete_sum_wgt <- sum(res_qp_discrete)


# Default PSO

time_pso <- system.time({
  pso_res <- pso(
    par = rep(0, ncol(pool_returns)),
    fn = function(x){
      x <- as.vector(round(x*nav/prices)*prices/nav)
      fitness <- calc_fit(x)
      constraints <- calc_const(x)
      return(fitness + 5*constraints)
    },
    lower = 0,
    upper = 1,
    control = list(
      s = 200, # swarm size
      c.p = 0.5, # inherit best
      c.g = 0.5, # global best
      maxiter = 200, # iterations
      w0 = 1.2, # starting inertia weight
      wN = 0, # ending inertia weight
      save_traces = F # save more information
    )
  )
})
pso_res$solution <- setNames(as.vector(round(pso_res$solution*nav/prices)*prices/nav), names(res_qp$solution))

res_pso_fit <- calc_fit(pso_res$solution)
res_pso_const <- calc_const(pso_res$solution)



# PSO with solve.QP starting position
time_pso_2 <- system.time({
  pso_2_res <- pso(
    par = res_qp$solution,
    fn = function(x){
      x <- as.vector(round(x*nav/prices)*prices/nav)
      fitness <- calc_fit(x)
      constraints <- calc_const(x)
      return(fitness + 5*constraints)
    },
    lower = 0,
    upper = 1,
    control = list(
      s = 200, # swarm size
      c.p = 0.5, # inherit best
      c.g = 0.5, # global best
      maxiter = 200, # iterations
      w0 = 1.2, # starting inertia weight
      wN = 0, # ending inertia weight
      save_traces = F # save more information
    )
  )
})
pso_2_res$solution <- setNames(as.vector(round(pso_2_res$solution*nav/prices)*prices/nav), names(res_qp$solution))
res_pso_2_fit <- calc_fit(pso_2_res$solution)
res_pso_2_const <- calc_const(pso_2_res$solution)

reactable(
  data.frame(
  "type" = c("solve.QP discrete", "PSO", "PSO with solve.QP as init solution"),
  "fitness" = c(res_qp_discrete_fit, res_pso_fit, res_pso_2_fit),
  "const_break" = c(res_qp_discrete_const, res_pso_const, res_pso_2_const),
  "sum_wgt" = c(res_qp_discrete_sum_wgt, sum(pso_res$solution), sum(pso_2_res$solution)),
  "time" = c(time_qp[3], time_pso[3], time_pso_2[3])
  ),
  columns = list(
    type = colDef(width = 120),
    fitness = colDef(format = colFormat(digits=5)),
    const_break = colDef(format = colFormat(digits=9)),
    sum_wgt = colDef(format = colFormat(digits=3)),
    time = colDef(format = colFormat(digits=3))
  ),
  style = list(fontFamily="Computer Modern, sans-serif", fontSize=13)
) %>% 
  html_save(., expand = c(-40,-20,-60,-20))
```


It can be seen that the rounded `solve.QP` solution still has a good fitness but the constraints are not satisfied. The PSO has no constraint breaks and better fitness than the rounded `solve.QP`. The PSO with `solve.QP` solution as starting position has beaten both approaches. This indicates that a hybrid approach consisting of both the `solve.QP` and afterwards the PSO for intelligent rounding with observed constraints would be a good heuristic for such problems in practice. 





