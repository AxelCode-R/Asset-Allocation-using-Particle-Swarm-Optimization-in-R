[["index.html", "Asset Allocation using Particle Swarm Optimization in R Preface", " Asset Allocation using Particle Swarm Optimization in R Axel Roth 2022-11-17 Preface |||in progress||| (soll vor dem TOC kommen denke ich) "],["abstract.html", "Abstract", " Abstract |||in progress||| (zusammenfassung: Vor dem TOC) motivation structure results "],["software-information-and-usage.html", "Chapter 1 Software information and usage 1.1 R-Version and Packages 1.2 Reproducibility 1.3 R-functions", " Chapter 1 Software information and usage |||in progress||| wie ich das buch schreibe, R markodwn bookdown und so und welche versionen ich nutze 1.1 R-Version and Packages 1.2 Reproducibility github und code im bookdown 1.3 R-functions zb plotly_save "],["open-data-sources.html", "Chapter 2 Open Data Sources 2.1 R-Functions", " Chapter 2 Open Data Sources To increase reproducibility, all data are free and can be loaded from the quantmod R package with the function getSymbols(). It is possible to choose between different data sources like yahoo-finance (default), alpha-vantage, google and others. 2.1 R-Functions The following functions were created to increase the ease of data collection with the quantmod R package, which can be found in the R/ directory in the attached github repository. 2.1.1 get_yf() This function is the main wrapper for collecting data with getSymbols() from yahoo-finance, and converts prices to returns with the pri_to_ret() function explained in 3.6.2. The output is a list containing prices and returns as xts objects. The arguments that can be passed to get_yf() are: tickers: Vector of symbols (asset names, e.g. APPL, GOOG, ) from =\"2018-01-01\": R-Date to = \"2019-12-31\": R-Date price_type = \"close\": Type of prices to be recorded (e.g. open, high, low, closed, adjusted) return_type = \"adjusted\": Type of return to be recorded (e.g. open, high, low, closed, adjusted) print = F: Should the function print the return of getSymbols() 2.1.2 buffer() To make data reusable and reduce compilation time, this function stores the data collected with get_yf(). It receives an R expression, evaluates it and stores it in the buffer_data/ directory under the specified name. If this name already exists, it loads the R object from the RData files without evaluating the expression. The evaluation and overwriting of the existing RData file can be forced with force=T. "],["mathfundations.html", "Chapter 3 Mathematical Fundations 3.1 Basic Operators 3.2 Formula Conventions 3.3 Return Calculation 3.4 Markowitz Modern Portfolio Theory (MPT) 3.5 Portfolio Math 3.6 R-Functions", " Chapter 3 Mathematical Fundations This chapter provides an overview of the mathematical calculations and conventions used in this thesis. It is important to note that most mathematical formulas are written in matrix notation. In most cases, this will result in a direct translation to R code. All necessary assumptions required for the modeled return structure are listed in this chapter so that any reader can understand the formulas given. It is important to note that reality is too complex and can only be partially modeled. Simple, basic models are used that do not stand up to reality, but these models or variations of them are commonly used in the financial world and have proven to be helpful. The complexity of solving advanced and basic models does not differ for the PSO because the dimension of the objective function is based on the number of elements that can be selected, see chapter 5. 3.1 Basic Operators The table below compares frequently used mathematical symbols with R code and their meaning: For a better understanding of the operators listed, the following examples are intended to illustrate the resulting dimensions and provide insight into the use of these operators. Matrix product: \\[\\times: \\ \\ \\mathbb{R}^{x \\times y} \\times \\mathbb{R}^{y \\times z} \\rightarrow \\mathbb{R}^{x \\times z} \\] with an example: \\[ \\begin{bmatrix}a_{1,1} &amp;\\cdots &amp; a_{1,y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{x,1} &amp; \\cdots &amp; a_{x,y} \\end{bmatrix} \\times \\begin{bmatrix}b_{1,1} &amp;\\cdots &amp; b_{1,z} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{y,1} &amp; \\cdots &amp; b_{y,z} \\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^y a_{1, i} \\cdot b_{i,1} &amp;\\cdots &amp; \\sum_{i=1}^y a_{1, i} \\cdot b_{i,z} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sum_{i=1}^y a_{x, i} \\cdot b_{i,1} &amp; \\cdots &amp; \\sum_{i=1}^y a_{x, i} \\cdot b_{i,z} \\end{bmatrix} \\] and for a vector \\[\\times: \\ \\ \\mathbb{R}^{1 \\times N} \\times \\mathbb{R}^{N \\times 1} \\rightarrow \\mathbb{R}\\] with an example: \\[ \\begin{bmatrix}a_{1} &amp;\\cdots &amp; a_{N}\\end{bmatrix} \\times \\begin{bmatrix}b_{1}\\\\ \\vdots \\\\ b_{N}\\end{bmatrix} = \\sum_{i=1}^N a_i \\cdot b_i \\] Outer product: \\[\\otimes: \\ \\ \\mathbb{R}^{x \\times 1} \\times \\mathbb{R}^{1 \\times y} \\rightarrow \\mathbb{R}^{x \\times y} \\] with an example: \\[ \\begin{bmatrix}a_{1}\\\\ \\vdots \\\\ a_{x}\\end{bmatrix} \\otimes \\begin{bmatrix}b_{1} &amp;\\cdots &amp; b_{y}\\end{bmatrix} = \\begin{bmatrix}a_{1} \\cdot b_{1} &amp;\\cdots &amp; a_{1} \\cdot b_{y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{x} \\cdot b_{1} &amp; \\cdots &amp; a_{x} \\cdot b_{y} \\end{bmatrix} \\] This thesis is specified for the use of R, so element-wise operators are very important to make code comparable with formulas. In mathematics, these operators are not common. For this reason, they must be explicitly specified. All element-wise operators work in the same way. Suppose \\(\\square\\) is one of the four element-wise operators, then this follows: \\[\\begin{align*} \\square &amp;: \\ \\ R^{x \\times y} \\times R^{x \\times y} \\rightarrow R^{x \\times y}\\\\ \\text{or }\\ \\square &amp;: \\ \\ R^{x} \\times R^{x \\times y} \\rightarrow R^{x \\times y}\\\\ \\text{or }\\ \\square &amp;: \\ \\ R \\times R^{x \\times y} \\rightarrow R^{x \\times y} \\end{align*}\\] with examples respectively: \\[ \\begin{bmatrix}a_{11} &amp;\\cdots &amp; a_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{x1} &amp; \\cdots &amp; a_{xy} \\end{bmatrix} \\square \\begin{bmatrix}b_{11} &amp;\\cdots &amp; b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{x1} &amp; \\cdots &amp; b_{xy} \\end{bmatrix} = \\begin{bmatrix}a_{11} \\square b_{11} &amp;\\cdots &amp; a_{1y} \\square b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{x1} \\square b_{x1} &amp; \\cdots &amp; a_{xy} \\square b_{xy} \\end{bmatrix} \\] or \\[ \\begin{bmatrix}a_{1} \\\\ \\vdots \\\\ a_{x} \\end{bmatrix} \\square \\begin{bmatrix}b_{11} &amp;\\cdots &amp; b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{x1} &amp; \\cdots &amp; b_{xy} \\end{bmatrix} = \\begin{bmatrix}a_{1} \\square b_{11} &amp;\\cdots &amp; a_{1} \\square b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{x} \\square b_{x1} &amp; \\cdots &amp; a_{x} \\square b_{xy} \\end{bmatrix} \\] or \\[ a \\ \\square \\begin{bmatrix}b_{11} &amp;\\cdots &amp; b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{x1} &amp; \\cdots &amp; b_{xy} \\end{bmatrix} = \\begin{bmatrix}a \\square b_{11} &amp;\\cdots &amp; a \\square b_{1y} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a \\square b_{x1} &amp; \\cdots &amp; a \\square b_{xy} \\end{bmatrix} \\] 3.2 Formula Conventions In mathematics, random variables are written in capital letters, which also applies to matrices. In order to allow an unambiguous assignment, the random variables are written in bold and in capital letters. For example, \\(A\\) should represent a matrix and \\(\\pmb{A}\\) should represent a random variable. 3.3 Return Calculation Any portfolio optimization strategy based on historical data must start with returns. These returns are calculated using adjusted closing prices, which show the percentage change over time. Adjusted closing prices reflect dividends and are adjusted for stock splits and rights offerings. These returns are essential for comparing assets and analyzing dependencies. 3.3.1 Simple Returns The default time frame for all raw data in this thesis is one working day and only simple rates of return are used. Assuming that there is an asset with price \\(p_{t_i}\\) on working day \\(t_i\\) and price \\(p_{t_{i+1}}\\) on the following working day \\(t_{i+1}\\), the simple rate of return for \\(t_{i+1}\\) can be calculated as follows: \\[ r_{i+1} = \\frac{p_{t_{i+1}}}{p_{t_i}}-1 \\] 3.4 Markowitz Modern Portfolio Theory (MPT) In 1952, Harry Markowitz published his first seminal paper, which had a significant impact on modern finance, primarily by outlining the implications of diversification and efficient portfolios. The definition of an efficient portfolio is a portfolio that has either the maximum expected return for a given risk target or the minimum risk for a given expected return target. A simple quote to define diversification might be, A portfolio has the same return but less variance than the sum of its parts. This is the case when assets are not perfectly correlated, as poor and good performances can offset each other, reducing the likelihood of extreme events. For more information, see (Maringer 2005). 3.4.1 Assumptions of Markowitz Portfolio Theory This thesis focuses on problems derived from Markowitzs portfolio theory (Markowitz 1959), without closed form solutions, which are studied in (Maringer 2005) by excluding short selling. The following list contains these types of Markowitz assumptions according to (Maringer 2005): Perfect market without taxes or transaction costs Assets are infinitely divisible Short sales are disallowed Expected returns, variances and covariances contain all information Investors are risk-averse, they will only accept greater risk if they are compensated with a higher expected return The assumption that the returns are normally distributed is not required, but is assumed in this case to simplify the problem. It is obvious that these assumptions are unrealistic in reality. More details on the requirements for using other distributions can be found in (Maringer 2005). 3.5 Portfolio Math Proofs of the basic calculations required for portfolio optimization, as shown in (Zivot 2021), are provided in this section. Returns are presented differently than in most sources, as this is the most common data format used in practice. Suppose there are \\(N\\) assets described by a return vector \\(\\pmb{R}\\) of random variables and a portfolio weight vector \\(w\\), respectively: \\[ \\pmb{R} = \\begin{bmatrix} \\pmb{R}_{1} &amp; \\pmb{R}_{2} &amp; \\cdots &amp; \\pmb{R}_{N} \\end{bmatrix} , \\ \\ w = \\begin{bmatrix} w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N} \\end{bmatrix} \\] In this thesis, each return is simplified as being normally distributed with \\(\\pmb{R}_i = \\mathbb{N}(\\mu_i, \\sigma_i^2)\\). As a result, linear combinations of normally distributed random variables are jointly normally distributed and have a mean, variance, and covariance that can be used to fully describe them. 3.5.1 Expected Returns The following formula can be used to get the expected returns of a vector with normally distributed random variables \\(\\pmb{R} \\in \\mathbb{R}^{1\\times N}\\): \\[\\begin{align*} E[\\pmb{R}] &amp;= \\begin{bmatrix} E[\\pmb{R}_{1}] &amp; E[\\pmb{R}_{2}] &amp; \\cdots &amp; E[\\pmb{R}_{N}] \\end{bmatrix}\\\\ &amp;= \\begin{bmatrix} \\mu_{1} &amp; \\mu_{2} &amp; \\cdots &amp; \\mu_{N} \\end{bmatrix} = \\mu \\end{align*}\\] and \\(\\mu_i\\) can be estimated in R using historical data and the formula for the geometric mean of returns (also called compound returns). The function to calculate the geometric mean of returns from an xts object can be found in 3.6.4. 3.5.2 Expected Portfolio Returns The following equation can be used to obtain the expected portfolio return \\(E[\\pmb{R}_p]\\) using the formulations from the section above and a weighting vector \\(w\\) (e.g. portfolio weights): \\[\\begin{align*} E[\\pmb{R}_p] &amp;= E[\\pmb{R} \\times w] = E[\\pmb{R}] \\times w \\\\ &amp;= \\begin{bmatrix} E[\\pmb{R}_{1}] &amp; E[\\pmb{R}_{2}] &amp; \\cdots &amp; E[\\pmb{R}_{N}] \\end{bmatrix} \\times \\begin{bmatrix} w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\mu_{1} &amp; \\mu_{2} &amp; \\cdots &amp; \\mu_{N} \\end{bmatrix} \\times \\begin{bmatrix} w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N} \\end{bmatrix} \\\\ &amp;= \\mu_{1} \\cdot w_1 + \\mu_{2} \\cdot w_2 + \\cdots + \\mu_{N} \\cdot w_{N} = \\mu_P \\end{align*}\\] 3.5.3 Covariance The general formula of the covariance matrix \\(\\textstyle\\sum\\) of a random vector \\(\\pmb{R}\\) with \\(N\\) normally distributed elements and \\(\\sigma_{i,j}\\) as correlation of two unique values is described as follows: \\[\\begin{align*} Cov(\\pmb{R}) &amp;= E[(\\pmb{R}-\\mu)^T \\otimes (\\pmb{R}-\\mu)] \\\\ &amp;= \\begin{bmatrix} \\sigma_1^2 &amp; \\sigma_{1,2} &amp; \\cdots &amp; \\sigma_{1,N} \\\\ \\sigma_{2, 1} &amp; \\sigma_2^2 &amp; \\cdots &amp; \\sigma_{2, N} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sigma_{N, 1} &amp; \\sigma_{N, 2} &amp; \\cdots &amp; \\sigma_N^2 \\\\ \\end{bmatrix}\\\\ &amp;=\\textstyle\\sum \\end{align*}\\] and can be estimated in R using the basis function cov() and historical data. The function cov_() in 3.6.1 can be used to calculate the covariance using the geometric mean to estimate the expected returns. 3.5.4 Portfolio Variance Let \\(\\pmb{R}\\) be a random vector with \\(N\\) normally distributed elements and \\(w\\) a weight vector. Assuming that the covariance matrix \\(\\sum\\) of \\(\\pmb{R}\\) is known, the variance of the linear combination of \\(\\pmb{R}\\) can be calculated as follows: \\[\\begin{align*} Var(\\pmb{R} \\times w) &amp;= E[(\\pmb{R} \\times w - \\mu \\times w)^2] \\\\ &amp;= E[((\\pmb{R} - \\mu) \\times w)^2] \\end{align*}\\] Since \\((\\pmb{R} - \\mu) \\times w\\) is a scalar, it can be transformed from \\(((\\pmb{R} - \\mu) \\times w)^2\\) to \\(((\\pmb{R} - \\mu) \\times w)^T \\cdot ((\\pmb{R} - \\mu) \\times w)\\) and results in: \\[\\begin{align*} Var(\\pmb{R} \\times w) &amp;= E[((\\pmb{R} - \\mu) \\times w)^T \\times ((\\pmb{R} - \\mu) \\times w)]\\\\ &amp;= E[(w^T \\times (\\pmb{R} - \\mu)^T) \\cdot ((\\pmb{R} - \\mu) \\times w)]\\\\ &amp;= w^T \\times E[(\\pmb{R} - \\mu)^T \\otimes (\\pmb{R} - \\mu)] \\times w \\\\ &amp;= w^T \\times Cov(\\pmb{R}) \\times w \\\\ &amp;= w^T \\times \\textstyle\\sum \\times w \\end{align*}\\] The same is true for an estimate of \\(Var(\\pmb{R} \\times w)\\) by using the estimate of \\(\\textstyle\\sum\\). 3.5.5 Portfolio Returns Suppose there are \\(N\\) assets that form a portfolio with weights \\(w_{t_0}\\) at time step \\(t_0\\), and the portfolio is to go through several time steps until \\(t_T\\) without rebalancing. What are the portfolio returns at each time step \\(t_i\\)? Clearly, assets with higher performance at the current time step will have a higher weight at the next time step. This can be done by adjusting the weights after each time step as a function of returns. Suppose we have a complete portfolio \\(\\textstyle\\sum w_{t_0} = 1\\) with a return matrix \\(R \\in \\mathbb{R}^{T \\times N}\\) and we want to calculate the portfolio returns \\(R_{t_1}^P\\). This can be done with the following two steps: \\[\\begin{align*} Z_{t_1} &amp;= (1+R_{t_1}) \\cdot t(w_{t_0})\\\\ R_{t_1}^P &amp;= \\sum_{n = 1}^N Z_{t_1, n} - 1 \\end{align*}\\] And since the portfolio was full in \\(t_0\\), the adjusted weights in \\(t_1\\) are \\(w_{t_1} = Z_{t_1}/\\sum_{n = 1}^N Z_{t_1, n}\\) (element-wise division). These new weights can be used in the next time step to replace the weights \\(w_{t_0}\\) in the above formula. The recursive formula for holding a portfolio with weights \\(\\textstyle\\sum w_{t_0} = 1\\) in \\(t_0\\) and return matrix \\(R \\in \\mathbb{R}^{T \\times N}\\), has portfolio return \\(R_{t_i}^P = \\textstyle\\sum_{n = 1}^N Z_{t_i, n} - 1\\) in \\(t_i\\) with \\(i=1, 2, \\cdots, T\\) for: \\[ Z_{t_i} = \\begin{cases} (1+R_{t_i})\\cdot t(w_{t_0}) &amp;\\text{ if }i=1\\\\ (1+R_{t_i})\\cdot \\frac{Z_{t_{i-1}}}{\\sum_{n = 1}^N Z_{t_{i-1, n}}} &amp;\\text{ if }i&gt;1 \\end{cases} \\] The requirement that the portfolio is full can be achieved by adding an additional weight to \\(w_{t_0}\\), which includes the residual \\(1-\\textstyle\\sum w_{t_0}\\) and an additional zero return vector to \\(R\\). This calculation of portfolio returns is implemented in the function calc_portfolio_returns() below. 3.6 R-Functions |||in progress||| 3.6.1 cov_() This function extends the base R function cov() by allowing the user to pass an expected value vector. This is used to calculate the covariance with expected returns based on the geometric mean instead of the arithmetic mean. 3.6.2 pri_to_ret() |||in progress||| ((prices to returns)) 3.6.3 ret_to_cumret() |||in progress||| ((returns to cumulated returns normalized to 100)) 3.6.4 ret_to_geomeanret() The geometric mean of returns is a better estimator than the arithmetic mean of returns because it captures the exact mean price changes over a period of time. The variance estimated from the daily returns is a daily variance, so the returns must have the same time base. This can be done by calculating the geometric mean of the returns from multiple daily returns. Assuming there is an asset with returns \\(r_1 = 0.01\\), \\(r_2=-0.03\\), and \\(r_3=0.02\\), it follows that the geometric mean return \\(r^{geom}\\) can be calculated as: \\[ r^{geom} = ((1+r_1) \\cdot (1+r_2) \\cdot (1+r_3))^{1/3}-1 = -0.0002353887 \\] And the advantage is that it is a daily average return that gives exactly the same result as the real return, that is: \\[ (1+r^{geom})^3 = (1+r_1) \\cdot (1+r_2) \\cdot (1+r_3) \\] This is not the case with the arithmetic mean of the returns. The general formula for calculating the geometric mean return of \\(n\\) days is: \\[ r^{geom} = (\\prod_{i=1}^n (1+r_i))^{\\frac{1}{n}}-1 \\] and as R code: ret_to_geomeanret &lt;- function(xts_ret){ sapply((1+xts_ret), prod)^(1/nrow(xts_ret))-1 } 3.6.5 calc_portfolio_returns() This is the implementation of a vectorial calculation of portfolio returns over multiple periods with a weighting vector weights at \\(t_0\\) and no re-balancing: calc_portfolio_returns &lt;- function(xts_returns, weights, name=&quot;portfolio&quot;){ if(sum(weights)!=1){ xts_returns$temp___X1 &lt;- 0 weights &lt;- c(weights, 1-sum(weights)) } res &lt;- cumprod((1+xts_returns)) * matrix( rep(weights, nrow(xts_returns)), ncol=length(weights), byrow=T) res &lt;- xts( rowSums(res/c(1, rowSums(res[-nrow(xts_returns),])))-1, order.by=index(xts_returns)) %&gt;% setNames(., name) return(res) } This function has the same results as the Return.portfolio() function from the PortfolioAnalytics package. References "],["activ-vs-passiv-portfolio-managment.html", "Chapter 4 Activ vs Passiv Portfolio Managment", " Chapter 4 Activ vs Passiv Portfolio Managment An active portfolio manager seeks to achieve positive alpha, i.e., excess return relative to the market, by using his knowledge, experience, and in-depth analysis of individual assets. Therefore, the manager assumes that the market is not efficient and tries to select mispriced assets to achieve excess returns. The passive portfolio manager, on the other hand, assumes that the market is efficient, meaning that prices reflect all available information, and attempts to replicate the average market return by constructing a diversified portfolio. He knows that stock movements follow a random walk and are therefore unpredictable for any individual stock. The passive manager achieves his goal with a quantitative strategy and assumes that the results are stable over time. The question arises which of the two portfolio management types is preferable? The scientists Fama and French analysed the returns of active and passive portfolio management by utilizing factor models which resulted in a wide range of now commonly used models to analyse the origin of returns. There theory is that passive investors get passive returns that have a alpha of zero before costs. This implicitly says that active investors combined have a alpha of zero before costs too. This means that if some active investors have a positive alpha, other active investors have made a negative alpha. In fact Fama and French analyzed this behavior more deeply in (Fama and French 2010) which indicated that value weighted professionally managed investment funds that primarily invest in the U.S. stock market have a slightly positive alpha in expense of active investors outside the professionally managed investment funds. |||in progress||| The fundation of Asset Management passiv vs activ studie https://www.scirp.org/journal/paperinformation.aspx?paperid=92983 gut gut file:///C:/Users/Axel/Desktop/Master-Thesis-All/Ziel%20was%20beantwortet%20werden%20soll/Quellen%20nur%20wichtige/Rasmussen2003_Book_QuantitativePortfolioOptimisat.pdf An_Index_Fund_Fundamentalist.pdf A Comparison of Active and Passive Portfolio Management.pdf References "],["challenges.html", "Chapter 5 Challenges of Passiv Investing 5.1 Mean-Variance Portfolio (MVP) 5.2 Index-Tracking Portfolio (ITP)", " Chapter 5 Challenges of Passiv Investing In this chapter, two common challenges of passive investing are analyzed to create simple use cases for testing the PSO. The first challenge is the mean-variance portfolio (MVP) from Markowitzs modern portfolio theory, which, simply put, is an optimal allocation of assets in terms of risk and return. The second challenge is the index tracking problem, which attempts to construct a portfolio with minimal tracking error to a given benchmark. 5.1 Mean-Variance Portfolio (MVP) Markowitz showed that diversifying risk across multiple assets reduces overall portfolio risk. This result was the beginning of the widely used modern portfolio theory, which uses mathematical models to create portfolios with minimal variance for a given return target. All such optimal portfolios for a given return target are called efficient and constitute the efficient frontier. The problem behind Markowitzs original MVP without constraints can be solved in a closed form, which is explained in (Zivot 2021). This type of MVP has no practical use, so only MVP problems with constraints and without closed forms are of interest in this thesis. 5.1.1 MVP: Problem Let there be \\(N\\) assets and their returns on \\(T\\) different days, creating a return matrix \\(R \\in \\mathbb{R}^{T \\times N}\\). Each element \\(R_{t,i}\\) contains the return of the \\(i\\)-th asset on day \\(t\\). The estimated covariance matrix of the returns is \\(\\textstyle\\sum \\in \\mathbb{R}^{N \\times N}\\) and the estimation of the expected returns are \\(\\mu \\in \\mathbb{R}^{N}\\). The MVP problem with the risk aversion parameter \\(\\lambda \\in [0,1]\\), as shown in (Maringer 2005), can be formalized as follows: \\[\\begin{equation} \\underset{w}{min} \\ \\ \\ \\lambda \\ w^T \\textstyle\\sum w - (1-\\lambda) \\ \\mu^T w \\tag{5.1} \\end{equation}\\] The risk aversion parameter \\(\\lambda\\) defines the tradeoff between risk and return. With \\(\\lambda = 1\\), the minimization problem contains only the variance term, leading to a minimum variance portfolio, and \\(\\lambda = 0\\) transforms the problem into a minimization of negative expected returns, leading to a maximum return portfolio. All possible portfolios created by \\(\\lambda \\in [0, 1]\\) define the efficient frontier. 5.1.2 MVP: Example All possible MVPs together define the efficient frontier, which is analyzed in this section without going into the details of its calculation. This example uses three assets (stocks: IBM, Google, Apple) and calculates the MVP for each \\(\\lambda\\). First, the daily returns of these three assets from 2018-01-01 to 2019-12-31 are loaded. returns &lt;- buffer( get_yf(tickers = c(&quot;IBM&quot;, &quot;GOOG&quot;, &quot;AAPL&quot;), from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot;)$returns, &quot;CPI_3_assets&quot; ) The cumulative daily returns are: The expected daily returns and the covariance matrix for the three assets can be estimated using the formulas from chapter 3: mu &lt;- ret_to_geomeanret(returns) cat0(&quot;estimation of expected daily returns:&quot;) mu cat(&quot;\\n&quot;) cov &lt;- as.matrix(nearPD(cov_(returns, mu))$mat) cat0(&quot;estimation of positiv definite covariance matrix:&quot;) cov estimation of expected daily returns: AAPL IBM GOOG 0.0011434115 -0.0001059164 0.0004870292 estimation of positiv definite covariance matrix: AAPL IBM GOOG AAPL 0.0003012226 0.0001177826 0.0001799097 IBM 0.0001177826 0.0002047608 0.0001158735 GOOG 0.0001799097 0.0001158735 0.0002728911 This is all the data necessary to solve the MVP problem with \\(\\lambda \\in \\{0.01, 0.02, ..., 0.99, 1\\}\\). All 100 portfolios are computed by solving a quadratic minimization problem with the long only (\\(w_i \\geq 0 \\ \\forall \\ i\\)) constraint and the weights should sum to 1. portfolios &lt;- data.frame() mu_and_var &lt;- NULL for(lambda in seq(0.01,1, 0.01)){ mat &lt;- list( Dmat = lambda * cov, dvec = (1 - lambda) * mu, Amat = t(rbind( rep(1, ncol(returns)), # sum up to 1 diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(returns)) # long only ), meq = 1 ) qp &lt;- solve.QP(Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq) port &lt;- xts(returns %*% qp$solution, order.by=index(returns)) mu_and_var &lt;- rbind( mu_and_var, data.frame(&quot;lambda&quot; = lambda, &quot;mu&quot; = mu %*% qp$solution, &quot;sd&quot; = sqrt(t(qp$solution) %*% cov %*% qp$solution)) ) portfolios &lt;- rbind( portfolios, qp$solution ) } portfolios &lt;- data.frame(portfolios) colnames(portfolios) &lt;- colnames(returns) The resulting portfolios are plotted in the daily \\(\\mu\\)-\\(\\sigma\\) diagram to create the efficient frontier: plot_ly(data = mu_and_var, type = &#39;scatter&#39;, mode=&quot;lines+markers&quot;) %&gt;% add_lines(y = ~mu, x = ~sd, name = &quot;efficient frontier&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;) %&gt;% add_trace(x = ~sd, y=~mu, mode=&quot;markers&quot;, name = &quot;lambda steps&quot;, type = &#39;scatter&#39;) %&gt;% layout( yaxis = list(title=list(text = &quot;mu&quot;, standoff = 10L), range=c(min(mu_and_var$mu)*0.9, max(mu_and_var$mu)*1.1)), xaxis = list(title=list(text = &quot;sigma&quot;, standoff = 10L), range=c(min(mu_and_var$sd)*0.95, max(mu_and_var$sd)*1.05)) ) %&gt;% #config(mathjax = &#39;cdn&#39;) %&gt;% html_save() The portfolio compositions for each \\(\\lambda\\) are: p &lt;- plot_ly(type=&quot;bar&quot;) %&gt;% layout(barmode=&quot;stack&quot;, xaxis = list(title=&quot;lambda&quot;, autorange = &quot;reversed&quot;), yaxis = list(title=&quot;weight&quot;), margin=list(b=70)) for(i in 1:ncol(portfolios)){ p &lt;- p %&gt;% add_trace(x=seq(0.01,1, 0.01), y=portfolios[, i], name = colnames(portfolios)[i]) } p %&gt;% config(mathjax = &#39;cdn&#39;) %&gt;% html_save() It can be observed that the portfolio with the lowest variance was obtained with a diversified composition of the three assets. With gradually decreasing \\(\\lambda\\), the minimization problem starts to ignore the variance, which leads to a portfolio investing more in the riskiest asset with the highest return. 5.1.3 MVP: Compare Estimators The above solution for the MVP problem was performed using a geometric mean to estimate the expected returns \\(\\mu\\) and was also used in the estimation of the covariance \\(\\textstyle\\sum\\). This raises the question of whether the result is different from the classical approach of estimating these parameters using the arithmetic mean. The following plot illustrates the efficient frontier created from the MVPs as a function of \\(\\lambda\\) using the arithmetic mean versus the geometric mean to estimate \\(\\mu\\). The weights of the MVPs using the geometric mean are used to calculate \\(\\mu\\) and \\(\\sigma\\) as a function of the arithmetic mean to make both efficient frontiers comparable: cov_ &lt;- function(mat, mean_vec=NULL){ if(is.null(mean_vec)){ mat_mean &lt;- matrix(data=1, nrow=nrow(mat)) %*% apply(mat, 2, mean) }else{ mat_mean &lt;- matrix(data=1, nrow=nrow(mat)) %*% mean_vec } mat &lt;- mat - mat_mean return((nrow(mat)-1)^(-1) * t(mat) %*% mat) } returns &lt;- buffer( get_yf(tickers = c(&quot;IBM&quot;, &quot;GOOG&quot;, &quot;AAPL&quot;), from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot;)$returns, &quot;CPI_3_assets&quot; ) # save geo to compare results mu_arit &lt;- apply(returns, 2, mean) #ret_to_geomeanret(returns) cov_arit &lt;- cov(returns) mu &lt;- ret_to_geomeanret(returns) #apply(returns, 2, mean) #ret_to_geomeanret(returns) cov &lt;- cov_(returns, mean_vec = mu) portfolios &lt;- data.frame() mu_and_var &lt;- NULL for(lambda in seq(0.01,1, 0.01)){ mat &lt;- list( Dmat = lambda * cov, dvec = (1 - lambda) * mu, Amat = t(rbind( rep(1, ncol(returns)), # sum up to 1 diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(returns)) # long only ), meq = 1 ) qp &lt;- solve.QP(Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq) port &lt;- xts(returns %*% qp$solution, order.by=index(returns)) mu_and_var &lt;- rbind( mu_and_var, data.frame(&quot;lambda&quot; = lambda, &quot;mu&quot; = mu_arit %*% qp$solution, &quot;sd&quot; = sqrt(t(qp$solution) %*% cov_arit %*% qp$solution)) ) portfolios &lt;- rbind( portfolios, qp$solution ) } portfolios &lt;- data.frame(portfolios) colnames(portfolios) &lt;- colnames(returns) all &lt;- data.frame(type=&quot;geo_mean&quot;, mu_and_var) mu &lt;- apply(returns, 2, mean) cov &lt;- cov(returns) portfolios &lt;- data.frame() mu_and_var &lt;- NULL for(lambda in seq(0.01,1, 0.01)){ mat &lt;- list( Dmat = lambda * cov, dvec = (1 - lambda) * mu, Amat = t(rbind( rep(1, ncol(returns)), # sum up to 1 diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(returns)) # long only ), meq = 1 ) qp &lt;- solve.QP(Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq) port &lt;- xts(returns %*% qp$solution, order.by=index(returns)) mu_and_var &lt;- rbind( mu_and_var, data.frame(&quot;lambda&quot; = lambda, &quot;mu&quot; = mu_arit %*% qp$solution, &quot;sd&quot; = sqrt(t(qp$solution) %*% cov_arit %*% qp$solution)) ) portfolios &lt;- rbind( portfolios, qp$solution ) } portfolios &lt;- data.frame(portfolios) colnames(portfolios) &lt;- colnames(returns) all &lt;- rbind(all, data.frame(type=&quot;arith_mean&quot;, mu_and_var)) plot_ly(data = all, type = &#39;scatter&#39;, mode=&quot;lines+markers&quot;, y = ~mu, x = ~sd, name=~type) %&gt;% # add_lines(data = all %&gt;% filter(type==&quot;geo_mean&quot;), y = ~mu, x = ~sd, name=&quot;geo_mean&quot;, type = &#39;scatter&#39;, mode=&quot;lines+markers&quot;) %&gt;% # #add_trace(data = all %&gt;% filter(type==&quot;geo_mean&quot;), x = ~sd, y=~mu, name=&quot;geo_mean&quot;, mode=&quot;markers&quot;, type = &#39;scatter&#39;) %&gt;% # add_lines(data = all %&gt;% filter(type==&quot;arith_mean&quot;), y = ~mu, x = ~sd, name=&quot;arith_mean&quot;, type = &#39;scatter&#39;, mode=&quot;lines+markers&quot;) %&gt;% #add_trace(data = all %&gt;% filter(type==&quot;arith_mean&quot;), x = ~sd, y=~mu, name=&quot;arith_mean&quot;, mode=&quot;markers&quot;, type = &#39;scatter&#39;) %&gt;% # add_lines(data = all %&gt;% filter(type==&quot;geo_mean_and_cov_with_arith&quot;), y = ~mu, x = ~sd, name=&quot;geo_mean_and_cov_with_arith&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;) %&gt;% # add_trace(data = all %&gt;% filter(type==&quot;geo_mean_and_cov_with_arith&quot;), x = ~sd, y=~mu, name=&quot;geo_mean_and_cov_with_arith&quot;, mode=&quot;markers&quot;, type = &#39;scatter&#39;) %&gt;% layout( #title = &quot;3-Asset MVP: arith_mean or geo_mean&quot;, yaxis = list(title=list(text = &quot;mu (arithmetic)&quot;, standoff = 10L), range=c(min(mu_and_var$mu)*0.9, max(mu_and_var$mu)*1.1)), xaxis = list(title=list(text = &quot;sigma (arithmetic)&quot;, standoff = 10L), range=c(min(mu_and_var$sd)*0.95, max(mu_and_var$sd)*1.05))#, # margin = list( # l = 10, # r = 10, # b = 70, # t = 50, # pad = 4 # ) ) %&gt;% config(mathjax = &#39;cdn&#39;) %&gt;% html_save() It can be seen, that both estimators produce portfolios on the same efficient frontier. If the aim of the MVP is to generate a portfolio with minimal variance for a given return target, the type of return needs to be specified to use the geometric or arithmetic mean. This specification will determine the type of estimator needed for the MVP. This analogy is not needed in the scope of this thesis, because the more generic portfolios specified with \\(\\lambda\\) are sufficient to create test-cases for the PSO. The later examples with the MVP will always use the geometric mean returns as estimation for the expected returns. 5.2 Index-Tracking Portfolio (ITP) Indices are baskets of assets that are used to track the performance of a particular asset group. For example, the well-known Standard and Poors 500 Index (S&amp;P 500 for short) tracks the 500 largest companies in the United States. Indices are not for sale and serve only to visualize the performance of a particular asset group, without incurring transaction costs. Such indices, or a combination of indices, are used by asset managers as benchmarks to compare the performance of their funds. Each fund has its own benchmark, which contains roughly the same assets that the manager might buy. If the fund underperforms its benchmark, it may indicate that the fund manager has made poor decisions. Therefore, fund managers strive to outperform their benchmarks through carefully selected investments. Past experience has shown that this is rarely achieved with active management by cost (Desmond Pace and Grima 2016). This has led to the growing popularity of passively managed funds whose goal is to track their benchmarks as closely as possible. This can be achieved through either full or sparse replication. Full replication is a portfolio that contains all the assets in the benchmark with the same weightings. The resulting performance equals the performance of the benchmark when transaction costs are neglected. The first problem is that a benchmark may contain assets that are not liquid or cannot be purchased. The second problem is the weighting scheme of the indices, because they are often weighted by their market capitalization, which changes daily. This would result in the need to reblanance daily and increase transaction costs to replicate the performance of the benchmark as closely as possible. To avoid this, sparse replications are used that contain only a fraction of the benchmarks assets. To do so, the portfolio manager must define his benchmark, which should overlap with the investment universe of his fund. He then reduces this universe, taking into account investor constraints and availability, to create a pool of possible assets. For example, a pool that replicates the S&amp;P 500 might consist of the one hundred highest-weighted assets in the S&amp;P 500. The ITP can be modeled in two ways analysed in (Iuliia Gavriushina 2019). 5.2.1 ITP with TEV objective (ITP-TEV) The classic and widely used model tries to reduce the tracking error variance (TEV) with the following formula: \\[ \\min \\ \\ Var(\\pmb{TE}) = Var(\\pmb{R}_{p}-\\pmb{R}_{bm}) \\] where the random tracking portfolio return is \\(\\pmb{R}_{p}\\) and the random benchmark return is \\(\\pmb{R}_{bm}\\). To obtain the portfolio weights \\(w\\), one needs to substitute the tracking portfolio return \\(\\pmb{R}_{p}\\) as follows: \\[ \\pmb{R}_{p} = \\pmb{R} \\times w \\] where \\(\\pmb{R}\\) is the random return vector containing the random return of each asset. The variance is then solved until a quadratic problem is presented as a function of portfolio weights \\(w\\): \\[\\begin{align*} Var(\\pmb{R}_{p}-\\pmb{R}_{bm}) &amp;= Var(\\pmb{R} \\times w - \\pmb{R}_{bm}) \\\\ &amp;= Var(\\pmb{R} \\times w) + Var(\\pmb{R}_{bm}) - 2 \\cdot Cov(\\pmb{R} \\times w,\\pmb{R}_{bm}) \\end{align*}\\] Now the three terms can be solved, starting with the simplest one. \\[ Var(\\pmb{R}_{bm}) = \\sigma_{bm}^2 \\] The variance of the portfolio can be solved with 3.5.4: \\[ Var(\\pmb{R} \\times w) = w^T \\times Cov(\\pmb{R}) \\times w \\] And the last term can be solved in the same way as in (Zivot 2021): \\[\\begin{align*} Cov(\\pmb{R} \\times w, \\pmb{R}_{bm}) &amp;= Cov(\\pmb{R}_{bm}, \\pmb{R} \\times w) \\\\ &amp;= E[(\\pmb{R}_{bm}-\\mu_{bm})(\\pmb{R} \\times w-\\mu_{\\pmb{R}} \\times w)] \\\\ &amp;= E[(\\pmb{R}_{bm}-\\mu_{bm})(\\pmb{R}-\\mu_{\\pmb{R}}) \\times w] \\\\ &amp;= E[(\\pmb{R}_{bm}-\\mu_{bm})(\\pmb{R}-\\mu_{\\pmb{R}})] \\times w \\\\ &amp;= Cov(\\pmb{R},\\pmb{R}_{bm}) \\times w \\end{align*}\\] This results in the final formulation of the ITP: \\[\\begin{align*} Var(\\pmb{R}_{p}-\\pmb{R}_{bm}) &amp; = Var(\\pmb{R} \\times w - \\pmb{R}_{bm}) \\\\ &amp; = Var(\\pmb{R} \\times w) - 2 \\cdot Cov(\\pmb{R} \\times w,\\pmb{R}_{bm}) + Var(\\pmb{R}_{bm}) \\\\ &amp; = w^T \\times Cov(\\pmb{R}) \\times w - 2 \\cdot Cov(\\pmb{R}_{bm}, \\pmb{R})^T \\times w + \\sigma_{bm}^2 \\tag{5.2} \\end{align*}\\] The above problem can be estimated using the formulas and functions created in chapter 3 and historical data \\(R\\) and \\(r_{bm}\\). The minimization problem of the ITP in the general structure required by many optimizers is: \\[ \\min\\limits_{w} \\ \\ \\frac{1}{2} \\cdot w^T \\times D \\times w -d^T \\times w \\] Minimization problems can ignore constant terms and global stretch coefficients and still find the same minimum. This leads to a general substitution of the ITP with TEV objective as follows: \\[ D = Cov(R) \\] and \\[ d = Cov(r_{bm}, R) \\] It is possible to add some basic constraints, as in the MVP to sum the weights to 1 and be long only. Despite the fact that this model is often used, it has a big disadvantage in that it cannot detect constant deviations in the returns. For this reason, the following model exists, which focuses on the mean square tracking error of returns (MSTE). 5.2.2 ITP with MSTE objective (ITP-MSTE) A good explanation of the ITP with MSTE objective can be found in (Badary 2017). The objective is to minimize the mean square tracking error (MSTE) of daily portfolio returns \\(r_{t, p}\\) and daily benchmark returns \\(r_{t, bm}\\) on \\(T\\) historical days: \\[ \\frac{1}{T} \\sum^T_{t=1}(r_{t, p}-r_{t, bm})^2 \\] The formula can be rewritten as vector norm: \\[ \\frac{1}{T} \\left\\Vert r_{p}-r_{bm} \\right\\Vert_2^2 \\] Which results in the following minimization with neglected stretching factor: \\[ min \\ \\ \\left\\Vert r_{p}-r_{bm} \\right\\Vert_2^2 \\] The portfolio returns \\(r_p\\) needs to be substituted to contain the portfolio weights \\(w\\) like in the TEV objective above. This results in the below transformation of the problem: \\[\\begin{align*} \\left\\Vert r_{p}-r_{bm} \\right\\Vert_2^2 &amp;= \\left\\Vert R \\times w-r_{bm} \\right\\Vert_2^2 \\\\ &amp;= (R \\times w-r_{bm})^T \\times (R \\times w-r_{bm}) \\\\ &amp;= (w^T \\times R^T-r_{bm}^T) \\times (R \\times w-r_{bm}) \\\\ &amp;= w^T \\times R^T \\times R \\times w - w^T \\times R^T \\times r_{bm} - r_{bm}^T \\times R \\times w + r_{bm}^T \\times r_{bm} \\end{align*}\\] The minimization and the fact that the scalars \\(w^T \\times R^T \\times r_{bm}\\) and \\(r_{bm}^T \\times R \\times w\\) are equal, transforms the problem to: \\[ \\min\\limits_{w} \\ \\ \\left\\Vert r_{p}-r_{bm} \\right\\Vert_2^2 = w^T \\times R^T \\times R \\times w - 2\\cdot r_{bm}^T \\times R \\times w \\] This leads to the equivalent general representation of the ITP with MSTE objective as follows: \\[ \\min\\limits_{w} \\ \\ \\frac{1}{2} \\cdot w^T \\times D \\times w - d^T \\times w \\] with \\[ D = R^T \\times R \\] and \\[ d = R^T \\times r_{bm} \\] 5.2.3 Example ITP This example shows the results of tracking the S&amp;P 500 with a tracking portfolio that can only invest in IBM, Apple and Google. Because the returns are calculated from adjusted closing prices, the index needs to represent dividends, stock splits and rights offerings too. This can be achieved by taking the S&amp;P 500 Total Return Index (SP500TR in short). The time frame ranges from 2018-01-01 till 2019-12-31 and the goal is to minimize the difference in returns between the portfolio and the benchmark. The fitted return changes of the ITP-TEV and ITP-MSTE are: pool_returns &lt;- buffer( get_yf(tickers = c(&quot;IBM&quot;, &quot;GOOG&quot;, &quot;AAPL&quot;), from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot;)$returns, &quot;CPI_3_assets&quot; ) bm_returns &lt;- buffer( get_yf(tickers = &quot;^SP500TR&quot;, from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot;)$returns, &quot;CPI_sp500tr&quot; ) %&gt;% setNames(., &quot;SP500TR&quot;) mat &lt;- list( Dmat = cov(pool_returns), dvec = cov(pool_returns, bm_returns), Amat = t(rbind( rep(1, ncol(pool_returns)), # sum up to 1 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(pool_returns)) # long only ), meq = 1 ) qp &lt;- solve.QP(Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq) composition_TEV &lt;- data.frame(&quot;type&quot;=&quot;ITP-TEV&quot;, t(setNames(qp$solution, colnames(pool_returns)))) port_returns_TEV &lt;- xts(pool_returns %*% qp$solution, order.by=index(pool_returns)) %&gt;% setNames(., &quot;ITP-TEV&quot;) mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( rep(1, ncol(pool_returns)), # sum up to 1 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(pool_returns)) # long only ), meq = 1 ) qp &lt;- solve.QP(Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq) composition_MSTE &lt;- data.frame(&quot;type&quot;=&quot;ITP-MSTE&quot;, t(setNames(qp$solution, colnames(pool_returns)))) port_returns_MSTE &lt;- xts(pool_returns %*% qp$solution, order.by=index(pool_returns)) %&gt;% setNames(., &quot;ITP-MSTE&quot;) plotly_line_chart_xts(ret_to_cumret(cbind.xts(port_returns_TEV, port_returns_MSTE, bm_returns))) %&gt;% html_save() The ITP-TEV and the ITP-MSTE had almost the same results, which can be seen in the compositions below: type AAPL IBM GOOG 1 ITP-TEV 0.2588844 0.4163274 0.3247882 2 ITP-MSTE 0.2586717 0.4165150 0.3248133 References "],["analytic-solver-for-quadratic-programming-problems.html", "Chapter 6 Analytic Solver for Quadratic Programming Problems 6.1 Quadratic Programming (QP) 6.2 QP-Solver from quadprog 6.3 Example: Solving MVP Problem with solve.QP() 6.4 Example: Solving ITP-MSTE with solve.QP()", " Chapter 6 Analytic Solver for Quadratic Programming Problems The advantages and disadvantages of analytical solvers for quadratic programming problems are discussed in this chapter. It is beyond the scope of this thesis to explain the underlying mathematical principles of how a solver solves quadratic problems; only the applications and analysis are discussed. The main reason for dealing with analytic solvers for quadratic programming problems is to use them as a benchmark for PSO. 6.1 Quadratic Programming (QP) A quadratic program is a minimization problem of a function that returns a scalar value and consists of a quadratic term and a linear term that depend on the variable of interest. In addition, the problem may be constrained by several linear inequalities that bound the solution. The general formulation used is to find \\(x\\) that minimizes the following problem: \\[ \\min\\limits_{x} \\ \\frac{1}{2} \\cdot x^T \\times D \\times x - d^T \\times x \\] and is valid under the linear constraints: \\[ A^T \\times x \\geq b_0 \\] Some other sources notate the problem with different signs or coefficients, all of which are interchangeable with the above problem. In addition, the above problem has the same notation used in the R package quadprog, which reduces the substitution overhead. All modern programming languages have many solvers for quadratic problems. They differ mainly in the computation time for certain problems and the requirements. Some commercial QP solvers additionally accept more complex constraints, such as absolute (e.g., \\(|A^T \\times x| \\geq a_0\\)) or mixed-integer (e.g., \\(x \\in \\mathbb{N}\\)). Especially the mixed-integer constraint problems lead to a huge increase in memory requirements. 6.2 QP-Solver from quadprog The most common free QP-Solver used in R comes from the package quadprog, which consists of a single function called solve.QP(). Its implementation routine is the dual method of Goldfarb and Idnani published in (Goldfarb and Idnani 1982) and (Goldfarb and Idnani 1983). It uses the above QP with the condition that \\(D\\) must be a symmetric positive definite matrix. This means that \\(D\\in \\mathbb{R}^{N \\times N}\\) and \\(x^T D x &gt; 0 \\ \\forall \\ x \\in \\mathbb{R}^N \\setminus \\{\\vec{0}\\}\\), which is equivalent to all eigenvalues being greater than zero. In most cases this is not achieved by estimating the covariance matrix \\(\\sum\\), but it is possible to find the nearest positive definite matrix of \\(\\textstyle\\sum\\) using the function nearPD() from the matrix R package. The error encountered often does not exceed a percentage change in elements over \\(10^{-15} \\%\\), which is negligible for the context of this work. The function solve.QP() for an \\(N\\) dimensional vector of interest, has the following arguments, which are also found in the above formulation of a QP: Dmat: Symmetric positive definite matrix \\(D \\in \\mathbb{R}^{N \\times N}\\) of the quadratic term dvec: Vector \\(d \\in \\mathbb{R}^{N}\\) of the linear term Amat: Constraint matrix \\(A\\) bvec: Constraint vector \\(b_0\\) meq = 1: means that the first meq columns of \\(A\\) are treated as an equality constraint The return of solve.QP() is a list and contains, among others, the following attributes of interest: solution: Vector containing the solution \\(x\\) of the quadratic programming problem (e.g. portfolio weights) value: Scalar, the value of the quadratic function at the solution 6.3 Example: Solving MVP Problem with solve.QP() This section provides insights into the effects of diversification and the use of solve.QP() by creating ten different efficient frontiers from a pool of ten assets. Each efficient frontier \\(i \\in \\{1, 2, \\cdots, 10\\}\\) consists of \\(N_i = i\\) assets and is created by adding the asset with the next smallest variance first. After loading the returns for ten of the largest stocks in the U.S. market, the variance is calculated to rank all columns in ascending order of variance, as shown in the code below: returns_raw &lt;- buffer( get_yf( tickers = c(&quot;IBM&quot;, &quot;GOOG&quot;, &quot;AAPL&quot;, &quot;MSFT&quot;, &quot;AMZN&quot;, &quot;NVDA&quot;, &quot;JPM&quot;, &quot;META&quot;, &quot;V&quot;, &quot;WMT&quot;), from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot; )$returns, &quot;AS_10_assets&quot; ) # re-arrange: low var first vars &lt;- sapply(returns_raw, var) returns_raw &lt;- returns_raw[, order(vars, decreasing = F)] The next step is to create a function mvp() that has the arguments return and lambda. It computes the expected returns mu and the estimated positive definite covariance cov. It then solves an MVP problem with constraints \\(\\textstyle\\sum w_i = 1\\) and \\(w_i \\geq 0\\), which yields the key features mu, var and composition of the portfolio. mvp &lt;- function(returns, lambda){ tc &lt;- tryCatch({ mu &lt;- ret_to_geomeanret(returns) cov &lt;- as.matrix(nearPD(cov_(returns, mu))$mat) mat &lt;- list( Dmat = lambda * cov, dvec = (1-lambda) * mu, Amat = t(rbind( rep(1, ncol(returns)), # sum up to 1 diag( 1, nrow=ncol(returns), ncol=ncol(returns) ) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(returns)) # long only ), meq = 1 ) qp &lt;- solve.QP( Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq ) res &lt;- list( &quot;mu&quot; = mu %*% qp$solution, &quot;var&quot; = t(qp$solution) %*% cov %*% qp$solution, &quot;composition&quot; = setNames(qp$solution, colnames(returns)) ) TRUE }, error = function(e){FALSE}) if(tc){ return(res) }else{ return(list( &quot;mu&quot; = NA, &quot;var&quot; = NA, &quot;composition&quot; = NA )) } } Each \\(\\lambda \\in \\{0.01, 0.02, \\cdots, 1\\}\\) and each combination of ascending number of assets results in a portfolio that can be created with two for loops. df &lt;- data.frame( &quot;index&quot;=1, &quot;var&quot;=as.numeric(var(returns_raw[, 1])), &quot;return&quot; = as.numeric(ret_to_geomeanret(returns_raw[, 1])), row.names=NULL ) for(i in 2:ncol(returns_raw)){ returns &lt;- returns_raw[, 1:i] for(lambda in seq(0.01, 1, 0.01)){ res &lt;- mvp(returns, lambda) df &lt;- rbind( df, data.frame(&quot;index&quot;=i, &quot;var&quot;=res$var, &quot;return&quot; = res$mu) ) } } The result is filtered and names are added to represent the number of assets. Now the diagram can be created: df &lt;- df %&gt;% filter(!is.na(return)) %&gt;% distinct() %&gt;% mutate(name = paste0(&quot;n_&quot;, index)) %&gt;% arrange(name) %&gt;% mutate(name = factor(name, levels=paste0(&quot;n_&quot;, ncol(returns_raw):1))) max_show_sd &lt;- df %&gt;% group_by(index) %&gt;% summarise(max_x = max(var)) %&gt;% pull(max_x) %&gt;% mean() %&gt;% sqrt() plot_ly( data = df[df$index!=1,], x=~sqrt(var), y=~return, name=~name, mode=&quot;lines&quot;, type = &#39;scatter&#39;, color = ~name, colors = c(&quot;green&quot;, &quot;red&quot;) ) %&gt;% add_trace( data=df[df$index==1,], x=~sqrt(var), y=~return, showlegend=T, marker=list(color=&quot;red&quot;), mode=&quot;markers&quot;, name=&quot;n_1&quot;) %&gt;% layout( xaxis=list(range=c(sqrt(min(df$var))*0.9, max_show_sd), title=&quot;standard deviation&quot;), yaxis=list(range=c(min(df$return)*0.9, (max(df$return)+mean(df$return))*0.5), title=&quot;return&quot;)) %&gt;% html_save() It can be seen, that each asset added results in a minimum variance portfolio with smaller or equal standard deviation. Nevertheless, we started with the asset that has the smallest standard deviation of 0.012459. This is the effect of diversification mentioned by Markowitz. 6.4 Example: Solving ITP-MSTE with solve.QP() This example analyzes how many assets are needed to minimize the mean square error between the replication and historical returns of the SP500TR from 2018-01-01 to 2019-12-31. The constraints are set to be long only and the weights should sum to one. To gradually reduce the number of assets, the five assets with the lowest weights are discarded, and the remaining assets serve as the new asset pool for the next replication until only five assets remain. First, the required data can be downloaded from the R/ directory using existing functions. The function get_spx_composition() uses web scraping to read the components of wikipedia and converts them into monthly compositions of the SP500TR. The pool is formed from all assets present in the last month of the time frame, reduced by assets with missing values. The code below loads the returns of all assets in the pool and the SP500TR: from &lt;- &quot;2018-01-01&quot; to &lt;- &quot;2019-12-31&quot; spx_composition &lt;- buffer( get_spx_composition(), &quot;AS_spx_composition&quot; ) pool_returns_raw &lt;- buffer( get_yf( tickers = spx_composition %&gt;% filter(Date&lt;=to) %&gt;% filter(Date==max(Date)) %&gt;% pull(Ticker), from = from, to = to )$returns, &quot;AS_sp500_assets&quot; ) pool_returns_raw &lt;- pool_returns_raw[, colSums(is.na(pool_returns_raw))==0] bm_returns &lt;- buffer( get_yf(tickers = &quot;^SP500TR&quot;, from = from, to = to)$returns, &quot;AS_sp500tr&quot; ) %&gt;% setNames(., &quot;SP500TR&quot;) The required data is now available and the function for the ITP-MSTE can be created. It requires pool_returns with variable number of columns and the single-column matrix bm_returns. itp &lt;- function(pool_returns, bm_returns){ mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( rep(1, ncol(pool_returns)), # sum up to 1 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( 1, # sum up to 1 rep(0, ncol(pool_returns)) # long only ), meq = 1 ) qp &lt;- solve.QP( Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq ) res &lt;- list( &quot;var&quot; = as.numeric( var(pool_returns %*% qp$solution - bm_returns)), &quot;solution&quot; = setNames(qp$solution, colnames(pool_returns)) ) } The successive removal of assets can begin and the results are stored in res. res &lt;- NULL asset_pool &lt;- NULL n_assets &lt;- rev(seq(5, ncol(pool_returns_raw), 5)) for(i in n_assets){ temp &lt;- if(i==max(n_assets)){ itp(pool_returns_raw, bm_returns) }else{ asset_pool &lt;- names(sort(temp$solution, decreasing = T)[1:i]) itp( pool_returns_raw[, asset_pool], bm_returns ) } res &lt;- rbind( res, data.frame(&quot;N&quot;=i, &quot;var&quot;=temp$var, &quot;sd&quot;=sqrt(temp$var), row.names = NULL) ) # for later analysis if(length(asset_pool)==100){ assets_pool_100 &lt;- asset_pool save(assets_pool_100, file=&quot;data/assets_pool_100.rdata&quot;) } if(length(asset_pool)==50){ assets_pool_50 &lt;- asset_pool save(assets_pool_50, file=&quot;data/assets_pool_50.rdata&quot;) } } plot_ly(data=res, x=~N, y=~sd, mode=&quot;lines&quot;, type = &#39;scatter&#39;) %&gt;% layout(yaxis=list(range=c(0, mean(max(res$sd),mean(res$sd)) ))) %&gt;% html_save() It can be seen that the standard deviation stagnates at about \\(N=200\\). This leads to the conclusion that a sparse replication with two hundred assets is sufficient in this particular case to track the historical performance of the SP500TR over this period. References "],["particle-swarm-optimization-pso.html", "Chapter 7 Particle Swarm Optimization (PSO) 7.1 The Algorithm 7.2 pso() Function 7.3 Animation 2-Dimensional 7.4 Simple Constraint Handling 7.5 Example MVP 7.6 Example: ITP-MSTE 7.7 Pros and Cons for Continuous Problems 7.8 Discrete Problems 7.9 Example: Discrete ITP-MSTE", " Chapter 7 Particle Swarm Optimization (PSO) The PSO was developed by J. Kennedy as a global optimization method based on swarm intelligence and presented to the public in 1995 by Eberhart and Kennedy (James Kennedy 1995). The original PSO was intended to resemble a flock of birds flying through the sky without collisions. Therefore, its first applications were found in particle physics to analyze moving particles in high-dimensional spaces, which the name Particle recalls. Later, it was adapted in Evolutionary Computation to exploit a set of potential solutions in high dimensions and to find the optima by cooperating with other particles in the swarm (Konstantinos Parsopoulos 2002). Since it does not require gradient information, it is easier to apply than other global optimization methods. It can find the optimum by considering only the result of the function to be optimized. This means that the function can be arbitrarily complex and it is still possible to reach the global optimum. Other advantages are the low computational costs, since only basic mathematical operators are used,the extensibility and the simplicity. 7.1 The Algorithm Each particle \\(d\\) with position \\(x_d\\) moves in the search space \\(\\mathbb{R}^N\\) and has its own velocity \\(v_d\\) and remembers its previous best position \\(P_d\\). After each iteration, the velocity changes in the direction of the intrinsic velocity, the best previous position, and the global best position \\(p_g\\) of all particles. A position change from \\(i\\) to \\(i+1\\) can be calculated by the following two equations (Konstantinos Parsopoulos 2002): \\[\\begin{align*} v_d^{i+1} &amp;= wv_d^{i} + c_p r_1^{i(d)} (P_d^i - x_d^i) + c_g r_2^{i(d)} (p_g^i - x_d^i) \\\\ x_d^{i+1} &amp;= x_d^i + v_d^{i+1} \\end{align*}\\] Where \\(r_1^{i(d)}\\) and \\(r_2^{i(d)}\\) are uniformly distributed random numbers in \\([0, 1]\\). The cognitive parameter \\(c_p\\) acts as a weighting of the direction to its previous best position of the particle. This contrasts with the social parameter \\(c_g\\), which is a weighting of the direction to the global best position. The inertial weight \\(w\\) is crucial for the convergence behavior by remembering part of its previous trajectory. A study reviewed in (Konstantinos Parsopoulos 2002) showed that these parameters can be set to \\(c_p=c_g=0.5\\) and \\(w\\) should decrease from \\(1.2\\) to \\(0\\). However, some problems benefit from a more precise tuning of these parameters. To allow effortless translation to code, the above formula for \\(d = 1, 2, \\cdots, D\\) particles can be given in the following matrix notation: \\[\\begin{align*} V^{i+1} &amp;= w \\cdot V^{i} + c_p \\cdot \\vec{r}_1^{\\,i} \\cdot (P^i-X^i) + c_g \\cdot \\vec{r}_2^{\\,i} \\cdot (p_g^i - X^i) \\\\ X^{i+1} &amp;= X^i + V^{i+1} \\end{align*}\\] With current positions \\(X \\in \\mathbb{R}^{N \\times D}\\), current velocities \\(V \\in \\mathbb{R}^{N \\times D}\\), previous best positions \\(P \\in \\mathbb{R}^{N \\times D}\\), and global best position \\(p_g \\in \\mathbb{R}^{N}\\). The parameters \\(w\\), \\(c_p\\) and \\(c_g\\) are stile scalars. The random numbers \\(r_1\\) and \\(r_2\\) are replaced by the vectors \\(\\vec{r}_1\\) and \\(\\vec{r}_2\\), in which each element is a uniformly distributed random number generated in \\([0, 1]\\). 7.2 pso() Function In this section, a general PSO function is created that follows the structure of other optimization heuristics in R, in particular the existing PSO implementation from the R package pso. The key component of the problem is a objective function called fn(), which returns a scalar that needs to be minimized. The objective function mainly needs a vector pos that describes the position of one particle (e.g. weights). The other main parameter for the PSO function is par, which is a position of a particle used to derive the dimension of the problem and used as the initial position of one particle. The vector can contain only NAs, resulting in completely random starting positions. The last two arguments are lower and upper bounds (e.g. weights greater than 0 and less than 1). All other parameters have default values that can be overridden by passing a list called control. The resulting structure is: pso &lt;- function( par, fn, lower, upper, control = list() ){ } Before the main data structure can be initialized, some sample inputs must be created for the pso() function as described below: par &lt;- rep(NA, 2) fn &lt;- function(x){return(sum(abs(x)))} lower &lt;- -10 upper &lt;- 10 control = list( s = 10, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 100, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_traces = F # save more information ) Now it is time to initialize the random positions X, their fitness X_fit and their random velocities V with the function mrunif() which produces a matrix of uniformly distributed random numbers between lower and upper: X &lt;- mrunif( nr = length(par), nc=control$s, lower=lower, upper=upper ) if(all(!is.na(par))){ X[, 1] &lt;- par } X_fit &lt;- apply(X, 2, fn) V &lt;- mrunif( nr = length(par), nc=control$s, lower=-(upper-lower), upper=(upper-lower) )/10 The velocities are compressed by a factor of 10 to start with a maximum movement of one tenth of the space in each axis. The personal best positions P are the same as X and the global best position is the position with the smallest fitness: P &lt;- X P_fit &lt;- X_fit p_g &lt;- P[, which.min(P_fit)] p_g_fit &lt;- min(P_fit) The required data structure is available and the optimization can start with the calculation of the new velocities and the transformation of the old positions. When particles have left the valid space, they are pushed back to the edge and the velocities are set to zero. Then the fitness is calculated and the personal best and global best positions are saved if they have improved. trace_data &lt;- NULL for(i in 1:control$maxiter){ # move particles V &lt;- (control$w0-(control$w0-control$wN)*i/control$maxiter) * V + control$c.p * t(runif(ncol(X)) * t(P-X)) + control$c.g * t(runif(ncol(X)) * t(p_g-X)) X &lt;- X + V # set velocity to zeros if not in valid space V[X &gt; upper] &lt;- 0 V[X &lt; lower] &lt;- 0 # move into valid space X[X &gt; upper] &lt;- upper X[X &lt; lower] &lt;- lower # evaluate objective function X_fit &lt;- apply(X, 2, fn) # save new previews best P[, P_fit &gt; X_fit] &lt;- X[, P_fit &gt; X_fit] P_fit[P_fit &gt; X_fit] &lt;- X_fit[P_fit &gt; X_fit] # save new global best if(any(P_fit &lt; p_g_fit)){ p_g &lt;- P[, which.min(P_fit)] p_g_fit &lt;- min(P_fit) } } The best fitness after \\(100\\) iterations is 0.0000613 and the best possible solution is \\(0\\). # load default PSO source(&quot;R/PSO_functions.R&quot;) 7.3 Animation 2-Dimensional This section provides insights into the behavior of the PSO by visualizing multiple iterations in a GIF. The GIF works in Adobe Acrobat DC or in the Markdown/HTML version of this thesis. The amazing animation template and the objective function is inspired by (Rtichoke 2021). The PSO core from the above chapter was used to complete the pso() function and is tested here with seed 0. The objective is to minimize the following function (\\(f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\)): \\[ f(x, y) = -20\\cdot e^{-0.2 \\cdot \\sqrt{0.5 \\cdot ((x-1)^2 + (y-1)^2)}} \\ - e^{0.5 \\cdot ( cos(2\\cdot \\pi \\cdot x) + cos(2\\cdot \\pi \\cdot y))} + e + 20 \\] The following code runs the PSO and tries to minimize the objective function: set.seed(0) f &lt;- function(pos){ -20 * exp(-0.2 * sqrt(0.5 *((pos[1]-1)^2 + (pos[2]-1)^2))) - exp(0.5*(cos(2*pi*pos[1]) + cos(2*pi*pos[2]))) + exp(1) + 20 } res &lt;- pso( par = rep(NA, 2), fn = f, lower = -10, upper = 10, control = list( s = 10, maxiter = 30, w0 = 1.2, save_traces = T ) ) The function f has many local minima and a global minima at \\((1,1)\\) with the value \\(0\\). The background color scale ranges from 0 as red to 20 as purple. The PSO has 10 particles, iterated 30 times with an inertia weight decreasing from 0.8 to 0. The iterations are visualized in the following GIF: 7.4 Simple Constraint Handling The simplest method for dealing with constraints is the penalty method, which takes into account the intensity of constraint breaks by increasing the objective value of a minimization problem. The two common problems studied in the last two chapters are quadratic problems with the same structure. This can be used to create a generic constraint handling function for these particular QPs. Both problems must satisfy the following equation: \\[ A^T \\times x \\geq b_0 \\] To calculate a value for the intensity of constraint breaks, the above inequality gets subtracted by \\(b_0\\) and defines: \\[ c := A^T \\times x - b_0 \\] All negative elements in the vector \\(c\\) represent constraint breaks that are squared and summed to extract a value that describes the intensity of constraint breaks like follows: \\[ c_{break} = \\sum p(c_i) \\cdot c_i^2 \\] with \\[ p(x) = \\begin{cases} 0 &amp;\\text{ if }x \\geq 0\\\\ x &amp;\\text{ if }x &lt; 0 \\end{cases} \\] By following the name conventions of solve.QP(), a list named mat is created in the parent environment, that contains the necessary inputs. The generic R function to calculate the constraint breaks can be defined as follows: calc_const &lt;- function(x){ const &lt;- t(mat$Amat) %*% x - mat$bvec sum(pmin(0, const)^2) } In contrast to the solve.QP(), its difficult for the PSO to find a feasible point, if equality constraints are used, which is why the equality constraint \\(\\textstyle\\sum w_i = 1\\) is reduced to \\(0.99 \\leq \\textstyle\\sum w_i\\) and \\(\\textstyle\\sum w_i \\leq 1\\). The new objective function fn() consists of two parts. The first part is to evaluate the unconstrained objective of the QP with the following function: calc_fit &lt;- function(x){ 0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x } The second part is the function calc_const(). Since breaking constraints is much worse than losing fitness, it must have a higher intensity (e.g. 10) which must be fine-tuned. This results in the final fn() function composition: fn &lt;- function(x){ fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness + 10 * constraints) } This approach to dealing with constraints is called the penalization method and is definitely the most straightforward approach. Its disadvantage is the fact that the PSO has to find a balance between the violation of constraints and the goal. As explained in (Mauro S. Innocente 2008), there are three other constraint handling methods, but the results show that none of them is superior. The treatment of constraints should be chosen appropriately for the given problem. For example, it may be useful to use the feasibility preservation technique to obtain a solution that is guaranteed not to break any constraints. The disadvantages here are longer computation time and less exploration of particles, since only feasible solutions can be stored as personal or global best solutions. 7.5 Example MVP This example uses the solve.QP() approach from section 6.3 with ten assets as the benchmark. Briefly, the goal is to create an MVP from ten of the largest U.S. stocks between 2018-01-01 and 2019-12-31 for each possible \\(\\lambda\\). The PSO has 300 particles and 200 iterations for each lambda. The starting position is the equally weighted vector \\(v\\) with \\(\\textstyle\\sum v_i=1\\). The main characteristics of all portfolios created with the solve.QP() compared to the PSO are shown below: set.seed(0) returns_raw &lt;- buffer( get_yf( tickers = c(&quot;IBM&quot;, &quot;GOOG&quot;, &quot;AAPL&quot;, &quot;MSFT&quot;, &quot;AMZN&quot;, &quot;NVDA&quot;, &quot;JPM&quot;, &quot;META&quot;, &quot;V&quot;, &quot;WMT&quot;), from = &quot;2018-01-01&quot;, to = &quot;2019-12-31&quot; )$returns, &quot;AS_10_assets&quot; ) # re-arrange: low var first vars &lt;- sapply(returns_raw, var) returns_raw &lt;- returns_raw[, order(vars, decreasing = F)] mvp_QP &lt;- function(returns, lambda){ tc &lt;- tryCatch({ mu &lt;- ret_to_geomeanret(returns) cov &lt;- as.matrix(nearPD(cov(returns))$mat) mat &lt;- list( Dmat = lambda * cov, dvec = (1-lambda) * mu, Amat = t(rbind( -rep(1, ncol(returns)), # sum w &lt;= 1 rep(1, ncol(returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(returns)) # long only ), meq = 0 ) qp &lt;- solve.QP( Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq ) res &lt;- list( &quot;mu&quot; = mu %*% qp$solution, &quot;var&quot; = t(qp$solution) %*% cov %*% qp$solution, &quot;composition&quot; = setNames(qp$solution, colnames(returns)) ) TRUE }, error = function(e){FALSE}) if(tc){ return(res) }else{ return(list( &quot;mu&quot; = NA, &quot;var&quot; = NA, &quot;composition&quot; = NA )) } } mvp_PSO &lt;- function(returns, lambda, silent = T){ tc &lt;- tryCatch({ mu &lt;- ret_to_geomeanret(returns) cov &lt;- cov(returns) mat &lt;- list( Dmat = lambda * cov, dvec = (1-lambda) * mu, Amat = t(rbind( -rep(1, ncol(returns)), # sum w &lt;= 1 rep(1, ncol(returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(returns), ncol=ncol(returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(returns)) # long only ), meq = 0 ) calc_fit &lt;- function(x){ 0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x } calc_const &lt;- function(x){ const &lt;- t(mat$Amat) %*% x - mat$bvec sum(pmin(0, const)^2) } pso_res &lt;- pso( par = rep(1/ncol(returns), ncol(returns)), fn = function(x){ fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness + 10 * constraints) }, lower = 0, upper = 1, control = list( s = 300, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 200, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_traces = F, # save more information save_fit = F ) ) if(!silent){ p0(&quot;constraint: &quot;, sum(calc_const(pso_res$solution))) p0(&quot;fitness: &quot;, calc_fit(pso_res$solution)) } res &lt;- list( &quot;mu&quot; = mu %*% pso_res$solution, &quot;var&quot; = t(pso_res$solution) %*% cov %*% pso_res$solution, &quot;composition&quot; = setNames(pso_res$solution, colnames(returns)), &quot;fit&quot; = calc_fit(pso_res$solution), &quot;constraint&quot; = sum(calc_const(pso_res$solution)) ) TRUE }, error = function(e){FALSE}) if(tc){ return(res) }else{ return(list( &quot;mu&quot; = NA, &quot;var&quot; = NA, &quot;composition&quot; = NA )) } } df &lt;- NULL runs &lt;- 100 for(i in 0:round((runs-1)*0.4)){ lambda &lt;- 1-i/runs temp &lt;- mvp_QP(returns = returns_raw, lambda = lambda) df &lt;- rbind(df, data.frame(&quot;type&quot;=&quot;QP_MVP&quot;, &quot;lambda&quot;=lambda, &quot;mu&quot;=temp$mu, &quot;var&quot;=temp$var, &quot;constraint&quot;=0)) temp &lt;- mvp_PSO(returns = returns_raw, lambda = lambda) df &lt;- rbind(df, data.frame(&quot;type&quot;=&quot;PSO_MVP&quot;, &quot;lambda&quot;=lambda, &quot;mu&quot;=temp$mu, &quot;var&quot;=temp$var, &quot;constraint&quot;=temp$constraint)) } df$sd = sqrt(df$var) df_qp &lt;- df[df$type==&quot;QP_MVP&quot; &amp; df$lambda %in% seq(1,0.8,-0.1),] df_diff &lt;- data.frame( &quot;mu_pso&quot; = df[df$type==&quot;PSO_MVP&quot;,]$mu, &quot;sd_pso&quot; = df[df$type==&quot;PSO_MVP&quot;,]$sd, &quot;mu_qp&quot; = df[df$type==&quot;QP_MVP&quot;,]$mu, &quot;sd_qp&quot; = df[df$type==&quot;QP_MVP&quot;,]$sd ) shapes &lt;- list() for(i in 1:nrow(df_diff)){ shapes[[i]] &lt;- list( type = &quot;line&quot;, y0 = df_diff[i,]$mu_pso, y1 = df_diff[i,]$mu_qp, yref = &quot;y&quot;, xref = &quot;x&quot;, x0 = df_diff[i,]$sd_pso, x1 = df_diff[i,]$sd_qp, line = list(color = &quot;lightgrey&quot;), layer=&#39;below&#39; ) } plot_ly( data = df, x=~sd, y=~mu, name=~type, mode=&quot;markers&quot;, type = &#39;scatter&#39;, color = ~type, colors = c(&quot;green&quot;, &quot;red&quot;) ) %&gt;% add_annotations( data=df_qp, x=~sd, y=~mu, text = ~paste0(&quot;lambda: &quot;,lambda), ay = -30, ax = -30 ) %&gt;% layout( xaxis=list(range=c(0.5*min(df$sd), 1.2*max(df[df$type==&quot;QP_MVP&quot;,]$sd)), showgrid = FALSE), yaxis=list(range=c(0.5*min(df$mu), 1.2*max(df[df$type==&quot;QP_MVP&quot;,]$mu)), showgrid = FALSE), shapes = shapes, legend = list(x = 0.1, y = 0.9) ) %&gt;% html_save() The corresponding portfolios for each \\(\\lambda\\) are connected with a grey line to visualize the error of the PSO. It turns out that it is possible to solve MVP problems with a PSO approach. It is noticable that some PSO runs were not able to reach the global minimum and thus show a deviation from the solve.QP() approach, which can often be fixed by repeated runs. 7.6 Example: ITP-MSTE The same ITP-MSTE solved with solve.QP() in 6.4 is used as the benchmark for the PSO. In summary, the goal is to create a portfolio that minimizes the mean square error of the returns of itself and the SP500TR between 2018-01-01 and 2019-12-31. The pool of assets includes all assets that are present in 2019-12-31 and have no missing values. The constraints are long only and the weights should sum to one. The parameters for the PSO are a swarm size of 100, 100 iterations, the inertia weight starts at \\(1.2\\) and decreases to zero, the upper bound is \\(0.05\\), and a starting position is the equally weighted vector \\(v\\) with \\(\\textstyle\\sum v_i=1\\). The PSO was run ten times, and the aggregated best and mean runs are compared to the solve.QP() approach for seed 0 in the table below: set.seed(0) from &lt;- &quot;2018-01-01&quot; to &lt;- &quot;2019-12-31&quot; spx_composition &lt;- buffer( get_spx_composition(), &quot;AS_spx_composition&quot; ) pool_returns_raw &lt;- buffer( get_yf( tickers = spx_composition %&gt;% filter(Date&lt;=to) %&gt;% filter(Date==max(Date)) %&gt;% pull(Ticker), from = from, to = to )$returns, &quot;AS_sp500_assets&quot; ) pool_returns_raw &lt;- pool_returns_raw[, colSums(is.na(pool_returns_raw))==0] bm_returns &lt;- buffer( get_yf(tickers = &quot;^SP500TR&quot;, from = from, to = to)$returns, &quot;AS_sp500tr&quot; ) %&gt;% setNames(., &quot;SP500TR&quot;) itp_QP &lt;- function(pool_returns, bm_returns){ mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( -rep(1, ncol(pool_returns)), # sum w &lt;= 1 rep(1, ncol(pool_returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(pool_returns)) # long only ), meq = 0 ) qp &lt;- solve.QP( Dmat = mat$Dmat, dvec = mat$dvec, Amat = mat$Amat, bvec = mat$bvec, meq = mat$meq ) res &lt;- list( &quot;value&quot; = qp$value, &quot;var&quot; = as.numeric( var(pool_returns %*% qp$solution - bm_returns)), &quot;solution&quot; = setNames(qp$solution, colnames(pool_returns)) ) } itp_PSO &lt;- function(pool_returns, bm_returns, silent = T){ mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( -rep(1, ncol(pool_returns)), # sum w &lt;= 1 rep(1, ncol(pool_returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(pool_returns)) # long only ), meq = 0 ) calc_fit &lt;- function(x){ as.numeric(0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x) } calc_const &lt;- function(x){ const &lt;- t(mat$Amat) %*% x - mat$bvec sum(pmin(0, const)^2) } pso_res &lt;- pso( par = rep(1/ncol(pool_returns), ncol(pool_returns)), fn = function(x){ fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+10*constraints) }, lower = 0, upper = 0.05, control = list( s = 200, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 100, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_traces = F # save more information ) ) if(!silent){ p0(&quot;constraint: &quot;, sum(calc_const(pso_res$solution))) p0(&quot;fitness: &quot;, calc_fit(pso_res$solution)) } res &lt;- list( &quot;composition&quot; = setNames(pso_res$solution, colnames(pool_returns)), &quot;fit&quot; = calc_fit(pso_res$solution), &quot;constraint&quot; = calc_const(pso_res$solution), &quot;var&quot; = as.numeric( var(pool_returns %*% pso_res$solution - bm_returns)) ) return(res) } df &lt;- NULL time &lt;- system.time( temp_qp &lt;- itp_QP(pool_returns_raw, bm_returns) ) df &lt;- data.frame(&quot;type&quot;=&quot;ITP-MSTE_QP&quot;, &quot;var&quot;=temp_qp$var, &quot;fitness&quot;=temp_qp$value, &quot;constraint&quot;=0, &quot;time&quot;=time[3]) for(i in 1:10){ time &lt;- system.time( temp_pso &lt;- itp_PSO(pool_returns = pool_returns_raw, bm_returns) ) df &lt;- rbind( df, data.frame( &quot;type&quot;=&quot;ITP-MSTE_PSO&quot;, &quot;var&quot;=temp_pso$var, &quot;fitness&quot;=temp_pso$fit, &quot;constraint&quot;=temp_pso$constraint, &quot;time&quot;=time[3] ) ) } df$sd &lt;- sqrt(df$var) df_summary &lt;- rbind( df %&gt;% filter(type == &quot;ITP-MSTE_QP&quot;), df %&gt;% filter(type == &quot;ITP-MSTE_PSO&quot;) %&gt;% filter(fitness == min(fitness)) %&gt;% mutate(type = &quot;ITP-MSTE_PSO_best&quot;), df %&gt;% filter(type == &quot;ITP-MSTE_PSO&quot;) %&gt;% group_by(type) %&gt;% summarise_all(., mean) %&gt;% mutate(type = &quot;ITP-MSTE_PSO_mean&quot;) ) rownames(df_summary) &lt;- NULL df_summary$var &lt;- round(df_summary$var, 12) df_summary$sd &lt;- round(df_summary$sd, 6) df_summary$fitness &lt;- round(df_summary$fitness, 7) df_summary$constraint &lt;- round(df_summary$constraint, 18) df_summary$time &lt;- round(df_summary$time, 1) reactable( df_summary %&gt;% select(type, sd, var, fitness, constraint, time), wrap = FALSE, #compact = T, columns = list( type = colDef(width=180), var = colDef(format = colFormat(digits=9), show =F), sd = colDef(format = colFormat(digits=5)), constraint = colDef(name = &quot;constraint break&quot;) )#, #theme = reactableTheme(style = list(fontFamily = &quot;-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, Arial, sans-serif&quot;)) ) %&gt;% html_save(., vwidth = 800) It can be seen that in all PSO runs, sufficient fitness was achieved with negligible constraint breaks, but much more computation time was required. 7.7 Pros and Cons for Continuous Problems A PSO approach has advantages and disadvantages, since on the one hand any problem can theoretically be solved, but it cannot be guaranteed that the solution is also optimal. In addition, the calculations take much longer than with the solve.QP() approach, which raises the question why a PSO approach should have any benefit at all. This is exactly the case, if the solution of the problem is no longer possible by the solve.QP() alone, as it is for example the case with mixed-integer-quadratic-problems. In these types of problems, the condition for the variable of interest \\(x\\) is to be a integer vector. These kind of problems could be solved by the solve.QP() approach only continuously and then rounded. However, this rounding error can become arbitrarily large, which is why the chances of the PSO approach to achieve a better solution are greater than with the solve.QP() approach. 7.8 Discrete Problems A continuous solution for a portfolio is not sufficient for practical purposes, since usually only integer amounts of assets can be purchased. Its even worse if lot sizes are needed, because these can only be bought in minimum denomination of e.g. ten thousand. Lot sizes are often used in fixed income products. The biggest drawbacks of rounding a continuous solution are the disregarding of conditions and the difference in the objective value, which often cant reach the new optimum. A solution with broken conditions is not acceptable in practice and a solve.QP() approach only produces one solution, which is why its insecure to hope for a sufficient solution after rounding. The PSO doesnt have these drawbacks and can be easily used for discrete problems by rounding the input of the objective function fn(). In a portfolio with net asset value (nav) consisting of only American stocks with weights \\(w_i\\) and closing prices \\(p_i\\) can be discretized to \\(w_i^d\\) by the following formula: \\[ w_i^d =\\text{round}(w_i \\cdot \\frac{\\text{nav}}{p_i})\\cdot \\frac{p_i}{\\text{nav}} \\] 7.9 Example: Discrete ITP-MSTE This example analyses the error of rounding a solution with the solve.QP() approach and compares it to a discrete PSO. A second discrete PSO is added, that takes the continuous solution of the solve.QP() and uses it as starting position of one particle. The ITP-MSTE focuses on replicating the SP500TR with its top 100 assets derived from the example with discarding in section 6.4 and tries to construct a portfolio with the constraints long only, \\(0.99 \\leq \\textstyle\\sum w_i \\leq 1\\) and \\(\\text{nav} = 10000\\) in the time frame from 2018-01-01 to 2019-12-31. The used prices are closing prices and both PSOs have 200 particles and 200 iterations. The results can be observed in the table below: set.seed(0) nav &lt;- 10000 from &lt;- &quot;2018-01-01&quot; to &lt;- &quot;2019-12-31&quot; spx_composition &lt;- buffer( get_spx_composition(), &quot;AS_spx_composition&quot; ) pool_data &lt;- buffer( get_yf( tickers = spx_composition %&gt;% filter(Date&lt;=to) %&gt;% filter(Date==max(Date)) %&gt;% pull(Ticker), from = from, to = to ), &quot;AS_sp500_asset_data&quot; ) load(&quot;data/assets_pool_100.rdata&quot;) pool_data$returns &lt;- pool_data$returns[, assets_pool_100] pool_data$prices &lt;- pool_data$prices[, assets_pool_100] bm_returns &lt;- buffer( get_yf(tickers = &quot;^SP500TR&quot;, from = from, to = to)$returns, &quot;AS_sp500tr&quot; ) %&gt;% setNames(., &quot;SP500TR&quot;) pool_returns &lt;- pool_data$returns mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( -rep(1, ncol(pool_returns)), # sum w &lt;= 1 rep(1, ncol(pool_returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(pool_returns)) # long only ), meq = 0 ) calc_fit &lt;- function(x){ as.numeric(0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x) } calc_const &lt;- function(x){ const &lt;- t(mat$Amat) %*% x - mat$bvec sum(pmin(0, const)^2) } # Default solve.QP time_qp &lt;- system.time({ res_qp &lt;- itp_QP(pool_data$returns, bm_returns) prices &lt;- last(pool_data$prices) res_qp_discrete &lt;- setNames(as.vector(round(res_qp$solution*nav/prices)*prices/nav), names(res_qp$solution)) }) res_qp_discrete_fit &lt;- calc_fit(res_qp_discrete) res_qp_discrete_const &lt;- calc_const(res_qp_discrete) res_qp_discrete_sum_wgt &lt;- sum(res_qp_discrete) # Default PSO time_pso &lt;- system.time({ pso_res &lt;- pso( par = rep(0, ncol(pool_returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness + 5*constraints) }, lower = 0, upper = 1, control = list( s = 200, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 200, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_traces = F # save more information ) ) }) pso_res$solution &lt;- setNames(as.vector(round(pso_res$solution*nav/prices)*prices/nav), names(res_qp$solution)) res_pso_fit &lt;- calc_fit(pso_res$solution) res_pso_const &lt;- calc_const(pso_res$solution) # PSO with solve.QP starting position time_pso_2 &lt;- system.time({ pso_2_res &lt;- pso( par = res_qp$solution, fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness + 5*constraints) }, lower = 0, upper = 1, control = list( s = 200, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 200, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_traces = F # save more information ) ) }) pso_2_res$solution &lt;- setNames(as.vector(round(pso_2_res$solution*nav/prices)*prices/nav), names(res_qp$solution)) res_pso_2_fit &lt;- calc_fit(pso_2_res$solution) res_pso_2_const &lt;- calc_const(pso_2_res$solution) reactable( data.frame( &quot;type&quot; = c(&quot;solve.QP discrete&quot;, &quot;PSO&quot;, &quot;PSO with solve.QP as init solution&quot;), &quot;fitness&quot; = c(res_qp_discrete_fit, res_pso_fit, res_pso_2_fit), &quot;const_break&quot; = c(res_qp_discrete_const, res_pso_const, res_pso_2_const), &quot;sum_wgt&quot; = c(res_qp_discrete_sum_wgt, sum(pso_res$solution), sum(pso_2_res$solution)), &quot;time&quot; = c(time_qp[3], time_pso[3], time_pso_2[3]) ), columns = list( fitness = colDef(format = colFormat(digits=5)), const_break = colDef(format = colFormat(digits=4)), sum_wgt = colDef(format = colFormat(digits=3)), time = colDef(format = colFormat(digits=3)) ) ) %&gt;% html_save() It can be seen that the rounded solve.QP() solution still has a good fitness but the constraints are not satisfied. The PSO has no constraint breaks and still reached a fitness close to the rounded solve.QP(). The PSO with solve.QP() solution as starting position has beaten both approaches. This indicates that a hybrid approach consisting of both the solve.QP() and afterwards the PSO for intelligent rounding with observed constraints would be a good heuristic for problems in practice. References "],["pso-variations.html", "Chapter 8 PSO Variations 8.1 Testproblem: Discrete ITP-MSTE 8.2 Function Stretching 8.3 Local PSO 8.4 Preserving Feasibility 8.5 Self-Adaptive Velocity 8.6 PSO R-Package", " Chapter 8 PSO Variations The standard PSO analyzed in the previous chapter is capable of solving a wide range of problems, but often gets stuck in local minima. In this chapter, different variants of the standard PSO are analyzed using a problem from the financial domain. The first variant is the PSO with function stretching, which is designed to allow the PSO to escape from local minima if they are discovered. The second variant is the local PSO, which is designed to reduce the probability of getting stuck in local minima by limiting the spread of information in the swarm. The third variant, the PSO with feasibility preservation, tries to optimize within the feasibility space and therefore provide only feasible solutions. The last variant is the PSO with self-adaptive velocity, which tries to adjust the control parameters according to certain rules and randomness. 8.1 Testproblem: Discrete ITP-MSTE All variants are tested on a discrete ITP-MSTE to replicate the SP500TR with a tracking portfolio consisting of the top 50 assets in the S&amp;P 500 derived from the example with discarding in section 6.4. The daily data used to solve the ITP ranges from 2018-01-01 to 2019-12-31, and the assets must be in the SP500TR at the end of the time frame and have no missing values. The tracking portfolio is discrete and has a net asset value of twenty thousand USD. The tracking portfolio is discretized using closing prices on 2019-12-31, and returns are calculated as simple returns using the adjusted closing prices. The maximum weighting for each asset is 10% to reduce the dimension space of the problem. Additional constraints are long only and portfolio weights \\(w\\) should satisfy \\(0.99 \\leq \\textstyle\\sum w_i \\leq 1\\). All variants are run 100 times and compared to 100 runs of the standard PSO function created in the previous chapter. The swarm size for the PSO and all variants is 50 and the iterations are set to 400. All PSOs start with an equally weighted portfolio that satisfies the condition \\(\\textstyle\\sum w_i = 1\\). The next plot analyzes the behavior of the 100 standard PSO runs in each iteration by plotting the median of the best fitness achieved in each iteration. The confidence bands for the 95% and 5% quantiles of the best fitness values are plotted in the same color as the median, with less transparency: nav &lt;- 20000 from &lt;- &quot;2018-01-01&quot; to &lt;- &quot;2019-12-31&quot; spx_composition &lt;- buffer( get_spx_composition(), &quot;AS_spx_composition&quot; ) pool_data &lt;- buffer( get_yf( tickers = spx_composition %&gt;% filter(Date&lt;=to) %&gt;% filter(Date==max(Date)) %&gt;% pull(Ticker), from = from, to = to ), &quot;AS_sp500_asset_data&quot; ) load(&quot;data/assets_pool_50.rdata&quot;) pool_data$returns &lt;- pool_data$returns[, assets_pool_50] pool_data$prices &lt;- pool_data$prices[, assets_pool_50] bm_returns &lt;- buffer( get_yf(tickers = &quot;^SP500TR&quot;, from = from, to = to)$returns, &quot;AS_sp500tr&quot; ) %&gt;% setNames(., &quot;SP500TR&quot;) pool_returns &lt;- pool_data$returns mat &lt;- list( Dmat = t(pool_returns) %*% pool_returns, dvec = t(pool_returns) %*% bm_returns, Amat = t(rbind( -rep(1, ncol(pool_returns)), # sum w &lt;= 1 rep(1, ncol(pool_returns)), # sum w &gt;= 0.99 diag(1, nrow=ncol(pool_returns), ncol=ncol(pool_returns)) # long only )), bvec = c( -1, # sum w &lt;= 1 0.99, # sum w &gt;= 0.99 rep(0, ncol(pool_returns)) # long only ), meq = 0 ) prices &lt;- last(pool_data$prices) calc_fit &lt;- function(x){ as.numeric(0.5 * t(x) %*% mat$Dmat %*% x - t(mat$dvec) %*% x) } calc_const &lt;- function(x){ const &lt;- t(mat$Amat) %*% x - mat$bvec sum(pmin(0, const)^2) } set.seed(0) SPSO_feasable_solutions &lt;- NULL df_SPSO &lt;- NULL for(i in 1:100){ res_SPSO_time &lt;- system.time({ res_SPSO &lt;- pso( par = rep(0, ncol(pool_data$returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 400, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_fit = T # save more information ) ) }) res_SPSO$solution &lt;- as.vector(round(res_SPSO$solution*nav/prices)*prices/nav) df_SPSO &lt;- rbind(df_SPSO, data.frame( &quot;run&quot; = i, suppressWarnings(rbind(data.frame( &quot;type&quot; = &quot;PSO&quot;, &quot;time&quot;=res_SPSO_time[3], &quot;const_break&quot;=calc_const(res_SPSO$solution), res_SPSO$fit_data %&gt;% select(iter, &quot;mean_fit&quot;=mean, &quot;best_fit&quot;=best) ))) ) ) if(calc_const(as.vector(round(res_SPSO$solution*nav/prices)*prices/nav)) == 0){ SPSO_feasable_solutions &lt;- cbind(SPSO_feasable_solutions, as.vector(round(res_SPSO$solution*nav/prices)*prices/nav)) } } df_res &lt;- df_SPSO %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() plot_ly() %&gt;% add_trace(data = df_res, x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res, x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res, x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The aggregate statistics of the last iterations of all 100 runs can be found in the table below: 8.2 Function Stretching PSO often gets stuck in local minima, i.e., if the current best global position is a local minima with a larger environment around it, with only higher fitness, it is hard for the PSO to escape and find the global minima. Function stretching tries to make the PSO escape from such local minima by transforming the fitness function in a way described in (Konstantinos Parsopoulos 2002). It states that after finding a local minimum, a two-stage transformation proposed by Vrahatis in 1996 can be used to stretch the original function so that the discovered local minimum is transformed into a maximum, but any position with less fitness remains unchanged. The two stages of the transformation with a discovered local minimum \\(\\bar{x}\\) are: \\[\\begin{equation} G(x) = f(x) + \\gamma_1 \\cdot \\| x-\\bar{x} \\| \\cdot (\\text{sign}(f(x)-f(\\bar{x}))+1) \\tag{8.1} \\end{equation}\\] and \\[\\begin{equation} H(x) = G(x) + \\gamma_2 \\cdot \\frac{\\text{sign}\\biggl(f(x)-f(\\bar{x})\\biggr)+1}{\\text{tanh}\\biggl( \\mu \\cdot (G(x)-G(\\bar{x})) \\biggr)} \\tag{8.2} \\end{equation}\\] The function \\(G(\\bar{x})\\) can be simplified to \\(f(\\bar{x})\\) and the \\(\\text{sign}()\\) function is defined as follows: \\[ \\text{sign}(x) = \\begin{cases} 1, &amp; \\text{if}\\ \\ x &gt; 0\\\\ 0, &amp; \\text{if}\\ \\ x = 0\\\\ -1, &amp; \\text{if}\\ \\ x &lt; 0 \\end{cases} \\] In the source it is suggested to select the following parameter values as default: \\[\\begin{align*} \\gamma_1 &amp;= 5000 \\\\ \\gamma_2 &amp;= 0.5 \\\\ \\mu &amp;= 10^{-10} \\end{align*}\\] It is difficult to interpret both transformations exactly, especially in higher dimensions. But some concepts can be recognized by looking only at the most important parts. The first transformation \\(G(x)\\) uplifts all values greater than or equal to the local minimum and increases the uplift as a function of distance from the local minimum. The second function \\(H(x)\\) also does not change any values below the local minimum and otherwise focuses on all values near the local minimum, stretching it to infinity and dropping steeply to repel particles. To better understand the transformation, it is used to stretch a simple function in \\(\\mathbb{R}^1\\) defined as follows: \\[ f(x) = cos(x)+\\frac{1}{10}\\cdot x \\] translated to the objective function: fn &lt;- function(pos){ cos(pos) + 1/10 * pos } and the domain of definition is chosen as \\(x \\in [-20, 20]\\). Suppose the PSO gets stuck in the local minimum at \\(\\bar{x} = \\pi - \\text{arcsin}(\\frac{1}{10}) \\approx 3.04\\). The original function fn and the transformed function fn_stretched, which matches \\(H(x)\\) in equation (8.2), are shown in the following graph: fn1 &lt;- function(pos, pos_best, pos_best_fit){ res &lt;- fn(pos) G &lt;- res + 5000 * sqrt(sum((pos - pos_best)^2))/length(pos) * (sign(res - pos_best_fit) + 1) H &lt;- G + 0.5 * (sign(res - pos_best_fit) + 1)/(tanh(10^(-10) * (G - pos_best_fit))) return(H) } X &lt;- seq(-20, 20, 0.001) x_best &lt;- pi-asin(1/10) x_best_fit &lt;- fn(x_best) p1 &lt;- plot_ly(x=X, y=sapply(X, fn), type=&quot;scatter&quot;, mode=&quot;lines&quot;, name=&quot;fn&quot;) %&gt;% add_trace(x=X, y=rep(fn(pi-asin(1/10)), length(X)), type=&quot;scatter&quot;, mode=&quot;lines&quot;, name=&quot;local_minima&quot;, line=list(dash=&quot;dot&quot;, color=&quot;grey&quot;)) p2 &lt;- plot_ly(x=X, y=sapply(X, fn1, pos_best=x_best, pos_best_fit=x_best_fit), type=&quot;scatter&quot;, mode=&quot;lines&quot;, name=&quot;fn_stretched&quot;, line=list(color=&quot;orange&quot;)) %&gt;% layout(yaxis=list(range=c(-2, 20)*10^5)) subplot(p1, p2, shareY=T, nrows=2) %&gt;% html_save(., vheight=700, vwidth=800) It can be seen that the fitness is stretched upward around the local minima \\(\\bar{x}\\), making it much easier for the PSO to move down the hill and fall into new minima with lower fitness. All the lower fitness regions remain unchanged, as can be seen in the zoomed version of the bottom diagram from above: 8.2.1 Implementation Since it is not possible to know if the PSO is stuck in a local minima, a stagnation value was added that increases by one if the global best particle does not change. After ten iterations with no change, a local minima is assumed and the transformation of the objective function takes place. After that, all personal best fitness values must be re-evaluated to work with the evaluated space and the stagnation value is set to zero. To prevent transformation just at the end of all iterations, the current iteration must be less than the maximum iteration minus twenty to allow transformation to occur. 8.2.2 Test PSO with Function Stretching The PSO with function stretching is called PSO-fnS and is evaluated on the test problem with \\(\\gamma_1 = 5000\\), \\(\\gamma_2 = 0.5\\) and \\(\\mu = 10^{-10}\\): set.seed(0) # R/PSO_functions.R : pso_fn_stretching() df &lt;- NULL for(i in 1:100){ res_pso_fns_time &lt;- system.time({ res_pso_fns &lt;- pso_fn_stretching( par = rep(0, ncol(pool_data$returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 400, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight fn_stretching = T, save_fit = T ) ) }) res_pso_fns$solution &lt;- as.vector(round(res_pso_fns$solution*nav/prices)*prices/nav) df &lt;- rbind(df, data.frame( &quot;run&quot; = i, suppressWarnings(data.frame( &quot;type&quot; = &quot;PSO-fnS&quot;, &quot;time&quot;=res_pso_fns_time[3], &quot;const_break&quot;=calc_const(res_pso_fns$solution), res_pso_fns$trace_fit %&gt;% select(iter, mean_fit, best_fit) )) ) ) } df_res &lt;- rbind(df_SPSO, df) %&gt;% #mutate(best_fit = best_fit +1) %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() plot_ly() %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-fnS&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO-fnS&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;,line = list(color=&quot;rgba(0, 102, 204, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-fnS&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO-fnS_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-fnS&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO-fnS_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), fillcolor = &quot;rgba(0, 102, 204, 0.3)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The aggregate statistics of the last iterations of all 100 runs can be found in the table below: 8.3 Local PSO A local PSO is a more general case of the global PSO, which is called the standard PSO. The only difference is the selection of the global best particle by defining a neighborhood. Each particle \\(x_i\\) has a neighborhood \\(N(x_i, \\bar{k})\\), and the global best particle in its neighborhood is called the local best particle of \\(x_i\\). If the neighborhood is chosen large enough to contain all particles, it corresponds to the standard PSO (global PSO). A simple definition of a neighborhood with \\(k\\) neighbors for particles \\(x_i\\) given in (Engelbrecht 2013) would be: \\[ N(x_i, k) = \\{ x_{i-\\bar{k}}, x_{i-(\\bar{k}-1)}, x_{i-(\\bar{k}-2)}, \\cdots, x_{i}, \\cdots, x_{i+(\\bar{k}-2)}, x_{i+(\\bar{k}-1)}, x_{i+\\bar{k}} \\} \\] with \\[ \\bar{k} = floor(\\frac{k}{2}) = \\lfloor \\frac{k}{2} \\rfloor \\] To illustrate this, the following figure defines the neighborhoods \\(N(x_4, 4)\\) and \\(N(x_1, 4)\\): In the latter case, it can be seen that the overflowing boundary will continue on the opposite side of the arranged particles. 8.3.1 Implementation First, the neighbors for each particle are stored in a suitable data structure before the main part of the PSO is executed. In the local version there is no global best particle, instead the global best particle for the neighborhood of each particle has to be calculated in each step. 8.3.2 Test Local PSO The PSO with particle neighborhoods is called PSO-local and evaluated on the test problem with \\(k=10\\): set.seed(0) # R/PSO_functions.R : pso_local() df &lt;- NULL for(i in 1:100){ res_pso_local_time &lt;- system.time({ res_pso_local &lt;- pso_local( par = rep(0, ncol(pool_data$returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 400, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_fit = T, k=10 ) ) }) res_pso_local$solution &lt;- as.vector(round(res_pso_local$solution*nav/prices)*prices/nav) df &lt;- rbind(df, data.frame( &quot;run&quot; = i, suppressWarnings(data.frame( &quot;type&quot; = &quot;PSO-local&quot;, &quot;time&quot;=res_pso_local_time[3], &quot;const_break&quot;=calc_const(res_pso_local$solution), res_pso_local$fit_data %&gt;% select(iter, &quot;mean_fit&quot;=mean, &quot;best_fit&quot; = best) )) ) ) } df_res &lt;- rbind(df_SPSO, df) %&gt;% #mutate(best_fit = best_fit +1) %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() plot_ly() %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-local&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO-local&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;,line = list(color=&quot;rgba(0, 102, 204, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-local&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO-local_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-local&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO-local_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), fillcolor = &quot;rgba(0, 102, 204, 0.3)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The aggregate statistics of the last iterations of all 100 runs can be found in the table below: It can be seen that it is superior to the standard PSO in this case. Especially in preventing stagnation in local minimas, which can be seen in the narrower quantile bands at the end. 8.4 Preserving Feasibility Other variants of PSO often provide solutions that are infeasible, resulting in the need to run them multiple times. To ensure that each solution is feasible, one of the inventors of PSO, Russel Eberhardt, in (Hu and Eberhardt 2002) explored a variant that preserves the feasibility of the solutions. To be precise, this is not a variant of its own, but a different method for handling constraints instead of the commonly used penalty method. Nevertheless, it must change the core of the PSO implementation, which is why it is classified as its own variant in this work. The difference to the standard PSO is that the initialization of the particles is repeated until all positions are feasible. After that, only feasible solutions are stored as global or personal best positions, resulting in a guaranteed feasible final solution. Even the first step is the most difficult to achieve in practice. To illustrate this, the following code tries to find a feasible position among a million randomly generated positions: set.seed(0) fn_const = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) constraints &lt;- calc_const(x) return(constraints) } time &lt;- system.time({ X &lt;- mrunif( nr = ncol(pool_data$returns), nc=10^6, lower=0, upper=0.1 ) X_const &lt;- apply(X, 2, fn_const) }) print(paste0(&quot;Feasable positions: &quot;, sum(X_const==0))) [1] &quot;Feasable positions: 0&quot; print(paste0(&quot;Elapsed time: &quot;, time[3])) [1] &quot;Elapsed time: 228.79&quot; rm(X, X_const) It can be seen that after a million randomly generated positions, there was not a single feasible position. For this reason, the first step was modified to start with only one feasible position, which was randomly determined from one of the final solutions of the standard PSO. To allow comparison with the standard PSO, the procedure was run again with the same starting positions. 8.4.1 Test Preserving Feasibility PSO In this section, we compare the PSO with feasibility preservation and the standard PSO. Both PSOs use the same feasible solutions as starting positions: set.seed(0) # R/PSO_functions.R : pso_preserving_feasibility() sel_sol &lt;- round(runif(100,1,ncol(SPSO_feasable_solutions))) df &lt;- NULL for(i in 1:100){ res_pso_preFe_time &lt;- system.time({ res_pso_preFe &lt;- pso_preserving_feasibility( par = SPSO_feasable_solutions[,sel_sol[i]], fn_fit = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) constraints &lt;- calc_const(x) fitness &lt;- calc_fit(x) return(fitness + 100*constraints) }, fn_const = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) constraints &lt;- calc_const(x) return(100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 200, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_fit = T, k=10 ) ) }) res_pso_preFe$solution &lt;- as.vector(round(res_pso_preFe$solution*nav/prices)*prices/nav) df &lt;- rbind(df, data.frame( &quot;run&quot; = i, suppressWarnings(data.frame( &quot;type&quot; = &quot;PSO-preFe&quot;, &quot;time&quot;=res_pso_preFe_time[3], &quot;const_break&quot;=calc_const(res_pso_preFe$solution), res_pso_preFe$fit_data %&gt;% select(iter, &quot;mean_fit&quot;=mean, &quot;best_fit&quot; = best) )) ) ) } df_SPSO2 &lt;- NULL for(i in 1:100){ res_SPSO_time &lt;- system.time({ res_SPSO &lt;- pso( par = SPSO_feasable_solutions[,sel_sol[i]], fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size c.p = 0.5, # inherit best c.g = 0.5, # global best maxiter = 200, # iterations w0 = 1.2, # starting inertia weight wN = 0, # ending inertia weight save_fit = T # save more information ) ) }) res_SPSO$solution &lt;- as.vector(round(res_SPSO$solution*nav/prices)*prices/nav) df_SPSO2 &lt;- rbind(df_SPSO2, data.frame( &quot;run&quot; = i, suppressWarnings(rbind(data.frame( &quot;type&quot; = &quot;PSO&quot;, &quot;time&quot;=res_SPSO_time[3], &quot;const_break&quot;=calc_const(res_SPSO$solution), res_SPSO$fit_data %&gt;% select(iter, &quot;mean_fit&quot;=mean, &quot;best_fit&quot;=best) ))) ) ) } df_res &lt;- rbind(df_SPSO2, df) %&gt;% #mutate(best_fit = best_fit +1) %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() df_res$iter &lt;- df_res$iter+400 plot_ly() %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-preFe&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO-preFe&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;,line = list(color=&quot;rgba(0, 102, 204, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-preFe&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO-preFe_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-preFe&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO-preFe_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), fillcolor = &quot;rgba(0, 102, 204, 0.3)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The aggregate statistics of the last iterations of all 100 runs can be found in the table below: The results differed only slightly, suggesting that PSO has no practical use in maintaining feasibility for finance-related problems such as ITP-MSTE. 8.5 Self-Adaptive Velocity A self-adaptive velocity PSO approach that attempts to reduce hyperparameters was analyzed in (Qinqin Fan 2014). The self-adaptive velocity is enabled by multiple velocity update schemes that are used randomly. In addition, all hyperparameters are self-adaptive in the way that each particle has its own coefficients \\(c_g\\), \\(c_p\\), and \\(w\\), which change after each iteration depending on the distance to maximum fitness, among other factors. The resulting PSO has no real hyperparameters to adjust, which allows it to be used as a general-purpose PSO. 8.5.1 Implementation The process of this PSO variant is too different from the standard PSO, so all changes are combined in steps: Initialize Each particle \\(d\\) must initialize its own inertial weight \\(w_d^0=0.5\\) and acceleration coefficients \\(c_{p,d}^0 = c_{g,d}^0 = 2\\). Velocity and positions Update the velocity of each particle \\(d\\) with the following switch-case for a uniform random number \\(r = \\text{Unif}(0,1)\\) in iteration \\(i+1\\): \\[\\begin{align*} v_d^{i+1} &amp;= w_d^i \\cdot v_d^{i}+c_{p,d}^i \\cdot Z \\cdot (P_{d}^i-x_d^i) + c_{g,d}^i \\cdot Z \\cdot (p_{g}^i-x_d^i) \\\\ Z &amp;= \\begin{cases} \\text{Unif}(0,1), &amp; \\text{if}\\ \\ r &gt; 0.8\\\\ \\text{Cauchy}(\\mu_1, \\sigma_1), &amp; \\text{if}\\ \\ 0.8 \\geq r &gt; 0.4\\\\ \\text{Cauchy}(\\mu_2, \\sigma_2), &amp; \\text{if}\\ \\ 0.4 \\geq r\\\\ \\end{cases} \\end{align*}\\] with \\[\\begin{align*} \\mu_1 &amp;= 0.1 \\cdot (1-(\\frac{i}{i_{max}})^2) + 0.3 \\\\ \\sigma_1 &amp;= 0.1 \\\\ \\mu_2 &amp;= 0.4 \\cdot (1-(\\frac{i}{i_{max}})^2) + 0.2 \\\\ \\sigma_2 &amp;= 0.4 \\end{align*}\\] and \\(\\text{Cauchy}(\\mu, \\sigma)\\) is a random number generated from the Cauchy distribution obtained with rcauchy() in R. The position update is the same as for the standard PSO. When a particle \\(d\\) has left the feasible search space in its coordinate \\(z\\), it is moved back with the following switch-case for \\(r = \\text{Unif}(0,1)\\): \\[ x_{d,z} = \\begin{cases} \\text{generate uniform in feasable space}, &amp; \\text{if}\\ \\ r &gt; 0.7\\\\ \\text{push back to boundary}, &amp; \\text{otherwise}\\ \\ \\\\ \\end{cases} \\] Fitness evaluation In the same way as for the standard PSO. Self-adaptive control parameters For an objective function \\(f()\\) and the maximum fitness of all particles \\(f_{max} = \\text{max}(f(X^{i+1}))\\), the parameters \\(w_d^{i}\\), \\(c_{p,d}^{i}\\) and \\(c_{g,d}^{i}\\) are adjusted for each particle \\(d\\) as follows: \\[\\begin{align*} W^i_d &amp;= \\frac{\\left| f(x_d^{i+1})-f_{max} \\right|}{\\sum_d\\left| f(x_d^{i+1})-f_{max} \\right|} \\\\ w_d^{i+1} &amp;= \\text{Cauchy}(\\sum_d W^i_d \\cdot w_d^{i}, 0.2) \\\\ c_{p,d}^{i+1} &amp;= \\text{Cauchy}(\\sum_d W^i_d \\cdot c_{p,d}^{i}, 0.3) \\\\ c_{g,d}^{i+1} &amp;= \\text{Cauchy}(\\sum_d W^i_d \\cdot c_{g,d}^{i}, 0.3) \\end{align*}\\] Then, the parameters are adjusted to their limits using the following formulas: \\[\\begin{align*} w_d^{i+1} &amp;= \\begin{cases} \\text{Unif}(0,1), &amp; \\text{if}\\ \\ w_d^{i+1} &gt; 1\\\\ \\text{Unif}(0,0.1), &amp; \\text{if}\\ \\ 0 &gt; w_d^{i+1}\\\\ w_d^{i+1}, &amp; \\text{otherwise} \\end{cases}\\\\ c_{p,d}^{i+1} &amp;= \\begin{cases} \\text{Unif}(0,1) \\cdot 4, &amp; \\text{if}\\ \\ c_{p,d}^{i+1} &gt; 4\\\\ \\text{Unif}(0,1), &amp; \\text{if}\\ \\ 0 &gt; c_{p,d}^{i+1}\\\\ c_{p,d}^{i+1}, &amp; \\text{otherwise} \\end{cases}\\\\ c_{g,d}^{i+1} &amp;= \\begin{cases} \\text{Unif}(0,1) \\cdot 4, &amp; \\text{if}\\ \\ c_{g,d}^{i+1} &gt; 4\\\\ \\text{Unif}(0,1), &amp; \\text{if}\\ \\ 0 &gt; c_{g,d}^{i+1}\\\\ c_{g,d}^{i+1}, &amp; \\text{otherwise} \\end{cases}\\\\ \\end{align*}\\] Update the best positions Update the personal best \\(P\\) and global best \\(p_g\\) positions as in the standard PSO. Repeat Steps 2 to 5 are repeated until the maximum iteration number \\(i_{max}\\) is reached. 8.5.2 Analyse Implementation The random use of the distributions for the velocity update increases the diversity of the swarm. The coefficients of iteration \\(i\\) with 100 maximum iterations are distributed as follows: It can be seen that the randomness of the motion increases compared to the uniform distribution and the center of the Cauchy distributions slowly decreases towards the absolute term. In addition, the two Cauchy distributions differ in explorability and exploitability, indicated by probabilities outside \\([0, 1]\\). Even more difficult to interpret is the adjusting of the control parameters. The value \\(W_d^i\\) is a weighting of the distances to the worst fitness, resulting in a higher weighting of the particles with good fitness. Later, the control parameters are adjusted using the Cauchy distribution with a weighted value of the previous control parameters as the center, giving higher weights to the control parameters that produced better fitness. This results in random control parameters distributed around the best previous control parameters. The resulting behavior can be described with a small quote, If exploration is beneficial, more exploration is done. If not, more is exploited. 8.5.3 Test PSO with Self-Adaptive Velocity The PSO with self-adaptive velocity is called PSO-SAvel and is evaluated for the test problem with the constants used in the implementation section: set.seed(0) # R/PSO_functions.R : pso_self_adaptive_velocity() df &lt;- NULL for(i in 1:100){ res_pso_SAvel_time &lt;- system.time({ res_pso_SAvel &lt;- pso_self_adaptive_velocity( par = rep(0, ncol(pool_data$returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size maxiter = 400, # iterations save_fit = T ) ) }) res_pso_SAvel$solution &lt;- as.vector(round(res_pso_SAvel$solution*nav/prices)*prices/nav) df &lt;- rbind(df, data.frame( &quot;run&quot; = i, suppressWarnings(data.frame( &quot;type&quot; = &quot;PSO-SAvel&quot;, &quot;time&quot;=res_pso_SAvel_time[3], &quot;const_break&quot;=calc_const(res_pso_SAvel$solution), res_pso_SAvel$fit_data %&gt;% select(iter, mean_fit=mean, best_fit=best) )) ) ) } df_res &lt;- rbind(df_SPSO, df) %&gt;% #mutate(best_fit = best_fit +1) %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() plot_ly() %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-SAvel&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO-SAvel&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;,line = list(color=&quot;rgba(0, 102, 204, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-SAvel&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO-SAvel_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-SAvel&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO-SAvel_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), fillcolor = &quot;rgba(0, 102, 204, 0.3)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The aggregate statistics of the last iterations of all 100 runs can be found in the table below: The results look very promising, and with fewer hyperparameters to fine-tune, this may be one of the best variants for general use of a PSO. 8.6 PSO R-Package In this section, the existing package pso from R is used to compare the results with the standard PSO. The PSO from the existing package is called PSO-pkg and has been reconfigured to have the same hyperparameters as the standard PSO. It must be said that the PSO-pkg differs in the initialization of the velocity and does not use the compression coefficient of one tenth of the initialized velocity. The diagram below compares the fitness: set.seed(0) df &lt;- NULL for(i in 1:100){ res_pso_pkg_time &lt;- system.time({ res_pso_pkg &lt;-suppressMessages(psoptim( par = rep(0, ncol(pool_data$returns)), fn = function(x){ x &lt;- as.vector(round(x*nav/prices)*prices/nav) fitness &lt;- calc_fit(x) constraints &lt;- calc_const(x) return(fitness+100*constraints) }, lower = 0, upper = 0.1, control = list( s = 50, # swarm size maxit = 400, # iterations w = c(1.2, 0), c.p = 0.5, c.g = 0.5, k = 50, p=1, type=&quot;SPSO2007&quot;, hybrid=F, rand.order=F, trace.stats = T, trace=T ) )) }) res_pso_pkg$par &lt;- as.vector(round(res_pso_pkg$par*nav/prices)*prices/nav) df_raw &lt;- data.frame(&quot;iter&quot;=res_pso_pkg$stats$it, &quot;best_fit&quot;=lapply(res_pso_pkg$stats$f, min) %&gt;% unlist() %&gt;% as.vector()) min_fit &lt;- df_raw[1,]$best_fit for(k in 2:nrow(df_raw)){ if(min_fit &lt; df_raw[k,]$best_fit){ df_raw[k,]$best_fit &lt;- min_fit }else{ min_fit &lt;- df_raw[k,]$best_fit } } df &lt;- rbind(df, data.frame( &quot;run&quot; = i, suppressWarnings(data.frame( &quot;type&quot; = &quot;PSO-pkg&quot;, &quot;time&quot;=res_pso_pkg_time[3], &quot;const_break&quot;=calc_const(res_pso_pkg$par), df_raw )) ) ) } df_res &lt;- bind_rows(df_SPSO, df) %&gt;% #mutate(best_fit = best_fit +1) %&gt;% group_by(iter, type) %&gt;% summarise(time_mean=mean(time), const_break_mean=mean(const_break), best_fit_q1 = quantile(best_fit, 0.05), best_fit_q3 = quantile(best_fit, 0.95), best_fit_mean = mean(best_fit), best_fit_median = quantile(best_fit, 0.5)) %&gt;% ungroup() plot_ly() %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(255, 51, 0, 0.4)&quot;), fillcolor = &quot;rgba(255, 51, 0, 0.4)&quot;, showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-pkg&quot;), x=~iter, y=~best_fit_median, name = &quot;PSO-pkg&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;,line = list(color=&quot;rgba(0, 102, 204, 1)&quot;)) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-pkg&quot;), x=~iter, y=~best_fit_q1, name = &quot;PSO-pkg_q1&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), showlegend=F) %&gt;% add_trace(data = df_res %&gt;% filter(type==&quot;PSO-pkg&quot;), x=~iter, y=~best_fit_q3, name = &quot;PSO-pkg_q3&quot;, mode=&quot;lines&quot;, type = &#39;scatter&#39;, fill=&quot;tonexty&quot;, line = list(color=&quot;rgba(0, 102, 204, 0.3)&quot;), fillcolor = &quot;rgba(0, 102, 204, 0.3)&quot;, showlegend=F) %&gt;% layout(yaxis=list(range=c(min(df_res[df_res$iter&gt;30,]$best_fit_q3)-0.0005, max(df_res[df_res$iter&gt;30,]$best_fit_q3)+0.0005), title=&quot;best fitness&quot;)) %&gt;% html_save() The existing PSO package is slightly different from the standard PSO, which is most likely due to the different velocity initialization. It is important to note that the existing PSO package has many features and variants that are disabled for this comparison. The aggregate statistics of the last iterations of all 100 runs can be found in the table below: References "],["real-life-itp-example.html", "Chapter 9 Real Life ITP Example 9.1 Transaction Costs 9.2 Rebalancing Constraint 9.3 Objective 9.4 Complete ITP Example", " Chapter 9 Real Life ITP Example In the previous chapters, the capabilities of a PSO and the quality of its results were analyzed based on the solution of a problem at a single point in time. In practice, the stability of future outcomes at multiple points in time is of greater interest. Therefore, the next sections provide additional constraints needed to simulate real portfolios over multiple rebalancing time points, first by adding transaction costs to the problem. For the first rebalancing time point, a problem is defined that simulates a portfolio manager who has a certain amount of cash and attempts to construct a portfolio from it, as described in the last section. After the first iteration, the portfolio manager must sell old assets and buy new ones. This, of course, incurs additional transaction costs and effort, so most portfolio managers consider a maximum rebalancing constraint that attempts to limit the amount of assets sold and purchased. The simulation of multiple rebalancing dates is called a backtest, which attempts to simulate the performance of a portfolio as a function of the previous portfolio and the historical data of each rebalancing date. Later, a full backtest of an ITP is evaluated and analyzed in a real-world environment. 9.1 Transaction Costs The cost of buying or selling assets must be considered as it can have a significant impact after several years of investment. There are many different costs that can be incurred depending on the concepts of the broker, the liquidity of the assets and the type of assets. For more information, see (GANTI 2022) or (nyse.com 2022). For simplicity, we focus on the situation of a retail investor using an online broker that charges a fixed fee per transaction for the U.S. stocks included in the SP500TR. Each transaction consists of one or more shares of an asset, and a transaction can be either a sale or a purchase. The fixed transaction fee is set at 1 USD, as is done by the online broker Trade Republic. The PSO can account for the transaction cost by increasing the objective value, but it is difficult to make the intensity of the transaction cost value comparable to the objective value. The objective value \\(v^o\\) of the ITP with MSTE approach, as in 5.2.2, is defined as: \\[ v^o = \\left\\Vert r_{p}-r_{bm} \\right\\Vert_2^2 = \\sum_{t=1}^T (r_{t,p}-r_{t,bm})^2 \\] The objective value \\(v^o\\) is the squared tracking error or, more precisely, the squared difference of the portfolio returns \\(r_p\\) and the benchmark returns \\(r_{bm}\\). To create a comparable value \\(v^{tc}\\) for transaction costs, we attempt to interpret the absolute loss due to transactions as the absolute error of return \\(r_{tc}\\) incurred in \\(t_0\\) (before the first data point in \\(t_1\\)). This absolute error \\(r_{tc}\\) can be calculated by counting the required transactions divided by the net asset value \\(nav\\). The required transactions can be calculated by comparing the shares vector of the previous portfolio \\(s^{prev}\\) and the shares vector of the rebalanced portfolio \\(s^{reba}\\). This results in the following formula for the absolute error return \\(r_{tc}\\): \\[ r_{tc} = \\frac{1 \\cdot \\sum_{n=1}^N g(s^{prev}_n-s^{reba}_n) }{nav} \\] with \\[ g(x) = \\begin{cases} 0 &amp;\\text{, if }\\ x = 0\\\\ 1 &amp;\\text{, else} \\end{cases} \\] This results in the following transaction costs value \\(v^{tc}\\): \\[ v^{tc} = \\left\\Vert r_{tc} \\right\\Vert_2^2 = r_{tc}^2 \\] The idea is to use the \\(v^{tc}\\) value and increase the objective value \\(v^o\\) of the ITP with MSTE approach, but these values are still not the same. The \\(v^o\\) is the sum of squared positive or negative errors and \\(v^{tc}\\) is a squared negative error. To increase the impact of the transaction cost, a coefficient \\(k\\) should increase the intensity, which leads to the following minimization problem: \\[ min \\ \\ v^o + k \\cdot v^{tc} \\] A suitable value for \\(k\\) could be calculated by dividing the number of training days by the number of days in the holding period increased by a factor of \\(2.5\\). This can be roughly interpreted as weighting the transaction cost error as the \\(2.5\\)-day error in the test period. For example, a 4-month training period with 96 working days and a holding period of 1 month with 24 working days yields the following value: \\[ k = \\frac{96}{24} \\cdot 2.5 = 10 \\] When the holding period is shortened, the intensity coefficient increases, which is a suitable behavior. Nevertheless, it should be analyzed and fine-tuned more. 9.2 Rebalancing Constraint The rebalancing constraint restricts the changes in weights by considering the previous portfolio weight vector \\(w^{prev}\\), which is recalculated using the previous shares vector and the rebalanced portfolio weight vector \\(w^{reba}\\). The value constrained by the rebalancing constraint should take into account the weights moved between assets and additional weights added. Example: the previous portfolio had a weight vector \\(w^{prev} = [0.5, 0.4]\\) as of the current rebalancing date and the rebalanced portfolio has a weight vector \\(w^{reba} = [0.8, 0.2]\\). The rebalanced weight from the second to the first asset is \\(0.2\\) and the additional weight added is \\(0.1\\), resulting in a rebalance of \\(0.2+0.1=0.3\\) weight. Below is the formula for calculating the rebalancing weight \\(w^{rb}\\): \\[ w^{rb} := \\frac{\\left\\Vert w^{prev}-w^{reba} \\right\\Vert_1 - |\\sum w^{prev} - \\sum w^{reba}|}{2}+|\\sum w^{prev} - \\sum w^{reba}| \\] and with a rebalancing constraint of, say, 30%, the rebalanced portfolio is feasible if: \\[ w^{rb} \\leq 0.3 \\] 9.3 Objective The goal is to simulate a tracking portfolio that tracks the SP500TR with a pool of 100 assets included in SP500TR over multiple rebalancing dates between 2016-05-01 and 2022-10-27 with one-month intervals. The pool of assets is created for each rebalancing date using the solve.QP() approach, continuously discarding assets as in section 6.4, with a maximum of 10 assets changing on each rebalancing date to reduce forced rebalancing. All considered assets have no missing values in the training period. In addition, the solve.QP() approach serves as a benchmark and the continuous solution is used as a particle position for the first rebalancing date. The tracking portfolio is solved using the self-adaptive velocity PSO from the last chapter, which gives stable results. The tracking portfolio has the following constraints: discrete number of stocks, long only, maximum weight of 10%, \\(0.96 \\leq \\sum w_i \\leq 0.995\\), rebalancing under 30% weight, considering transaction cost with diffrent values for \\(k\\), net asset value of 20000 USD, length of training period of four months and testing period of one month. Each PSO run uses 100 particles and iterates 100 times. The PSO is repeated until the constraints are satisfied. Then it is run four more times to improve the quality of the feasible solution. Each rebalancing portfolio is simulated with the portfolio return function from 3.5.5 until the next rebalancing date. In each step the weights and shares of the tracking portfolio are calculated and the shares are used to calculate the weights at the next rebalancing date. If assets are missing in the next asset pool, they are sold and reduce the net asset value due to transaction costs. The same is done by buying or selling any remaining assets. A rough illustration of the process can be found in the following figure: Backtest Process 9.4 Complete ITP Example The following charts visualize the test period of the whole backtests. The QP_MSTE_cont line represents the performance of the continuous solution using the ITP MSTE approach solved with solve.QP() and stays the same for all backtests. The discretized solution using the PSO is named PSO_MSTE_disc and the PSO_MSTE_disc_TE considers all transaction costs in its performance. Everything is compared to the SP500TR which is the objective to track. Furthermore there are used different values for the transaction costs intensity \\(k \\in \\{0, 10, 20, 30\\}\\) of each backtest which can be seen in the legends by 0tc, 10tc, 20tc and 30tc. Backtest for \\(k=0\\): and the statistics of the discretized PSO with considered transaction costs are: Backtest for \\(k=10\\): and the statistics of the discretized PSO with considered transaction costs are: Backtest for \\(k=20\\): and the statistics of the discretized PSO with considered transaction costs are: Backtest for \\(k=20\\): and the statistics of the discretized PSO with considered transaction costs are: It can be seen that increasing \\(k\\) tends to reduce the average transaction cost in USD. Since each backtest depends on different previous portfolios, further backtests are needed to confirm this result. The absolute loss of nav between the results of the PSO without and with transaction costs for each \\(k\\) can be found in the chart below: Another interesting result is that the solve.QP() approach with a pool of 100 assets had a slightly higher performance than the SP500TR, suggesting that the asset pool in that particular period consists of assets that performed relatively well. This can be inspected in the follwing chart, comparing only the solve.QP() approach and the SP500TR: References "],["conclusion.html", "Chapter 10 Conclusion", " Chapter 10 Conclusion asd "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
